{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d4e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75de026",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.load('2016_9_BERTopic_TopicDocumentsProbs_reduction.npy')\n",
    "bert_model = BERTopic.load('2016_9_BERTopic_model_2_2_raw_content')\n",
    "docs_topic_df = pd.read_csv('2016_9_BERTopic_TopicDocuments_reduction.csv', sep=';')\n",
    "topic_terms_df = pd.read_csv('2016_9_BERTopic_Terms.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c46ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#probs[:2]\n",
    "#bert_model.get_topic_freq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974591c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_zero = 0\n",
    "for prob in probs:\n",
    "    all_zero += 1\n",
    "    for p in prob:\n",
    "        if p > 0.053:\n",
    "            all_zero -= 1\n",
    "            break\n",
    "all_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fe5628",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 19\n",
    "words = bert_model.get_topic(idx)\n",
    "labels = []\n",
    "if words:\n",
    "    label = [word[0] for word in words[:5]]\n",
    "    label = f\"<b>Topic {idx}</b>: {'_'.join(label)}\"\n",
    "    label = label[:40] + \"...\" if len(label) > 40 else label\n",
    "    labels.append(label)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2f58ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0792f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f82c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_max_proba = []\n",
    "for prob in probs:\n",
    "    #topic_max_proba.append(max(prob))\n",
    "    topic_max_proba.append(prob[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39727b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_idx = np.argwhere(probs >= 0.0).flatten()\n",
    "vals = probs[labels_idx].tolist()\n",
    "\n",
    "# Create labels\n",
    "labels = []\n",
    "for idx in labels_idx:\n",
    "    words = bert_model.get_topic(idx)\n",
    "    if words:\n",
    "        label = [word[0] for word in words[:5]]\n",
    "        label = f\"<b>Topic {idx}</b>: {'_'.join(label)}\"\n",
    "        label = label[:40] + \"...\" if len(label) > 40 else label\n",
    "        labels.append(label)\n",
    "        print(idx)\n",
    "    #else:\n",
    "        #print(idx)\n",
    "        #print(probs[idx])\n",
    "        #vals.remove(probs[idx])\n",
    "        #vals.remove(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f68fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals[0]["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee24752",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa83dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "populated = [n for n in topic_max_proba if n == 0]\n",
    "len(populated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ba88b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_distribution(topic_model,\n",
    "                           probabilities: np.ndarray,\n",
    "                           min_probability: float = 0.015):\n",
    "    \"\"\" Visualize the distribution of topic probabilities\n",
    "\n",
    "    Arguments:\n",
    "        topic_model: A fitted BERTopic instance.\n",
    "        probabilities: An array of probability scores\n",
    "        min_probability: The minimum probability score to visualize.\n",
    "                         All others are ignored.\n",
    "        width: The width of the figure.\n",
    "        height: The height of the figure.\n",
    "\n",
    "    Usage:\n",
    "\n",
    "    Make sure to fit the model before and only input the\n",
    "    probabilities of a single document:\n",
    "\n",
    "    ```python\n",
    "    topic_model.visualize_distribution(probabilities[0])\n",
    "    ```\n",
    "\n",
    "    Or if you want to save the resulting figure:\n",
    "\n",
    "    ```python\n",
    "    fig = topic_model.visualize_distribution(probabilities[0])\n",
    "    fig.write_html(\"path/to/file.html\")\n",
    "    ```\n",
    "    <iframe src=\"../../tutorial/visualization/probabilities.html\"\n",
    "    style=\"width:1000px; height: 500px; border: 0px;\"\"></iframe>\n",
    "    \"\"\"\n",
    "    if len(probabilities[probabilities > min_probability]) == 0:\n",
    "        return [f'Topic {-1}'], [0]\n",
    "        '''raise ValueError(\"There are no values where `min_probability` is higher than the \"\n",
    "                         \"probabilities that were supplied. Lower `min_probability` to prevent this error.\")'''\n",
    "    if not topic_model.calculate_probabilities:\n",
    "        raise ValueError(\"This visualization cannot be used if you have set `calculate_probabilities` to False \"\n",
    "                         \"as it uses the topic probabilities. \")\n",
    "\n",
    "    # Get values and indices equal or exceed the minimum probability\n",
    "    labels_idx = np.argwhere(probabilities >= min_probability).flatten()\n",
    "    vals = probabilities[labels_idx].tolist()\n",
    "\n",
    "    # Create labels\n",
    "    labels = []\n",
    "    for idx in labels_idx:\n",
    "        words = topic_model.get_topic(idx)\n",
    "        if words:\n",
    "            #label = [word[0] for word in words[:5]]\n",
    "            #label = f\"<b>Topic {idx}</b>: {'_'.join(label)}\"\n",
    "            #label = label[:40] + \"...\" if len(label) > 40 else label\n",
    "            label = f'Topic {idx}'\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            vals.remove(probabilities[idx])\n",
    "\n",
    "    # Create Figure\n",
    "    '''\n",
    "    fig = go.Figure(go.Bar(\n",
    "        x=vals,\n",
    "        y=labels,\n",
    "        marker=dict(\n",
    "            color='#C8D2D7',\n",
    "            line=dict(\n",
    "                color='#6E8484',\n",
    "                width=1),\n",
    "        ),\n",
    "        orientation='h')\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Probability\",\n",
    "        title={\n",
    "            'text': \"<b>Topic Probability Distribution\",\n",
    "            'y': .95,\n",
    "            'x': 0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top',\n",
    "            'font': dict(\n",
    "                size=22,\n",
    "                color=\"Black\")\n",
    "        },\n",
    "        template=\"simple_white\",\n",
    "        width=width,\n",
    "        height=height,\n",
    "        hoverlabel=dict(\n",
    "            bgcolor=\"white\",\n",
    "            font_size=16,\n",
    "            font_family=\"Rockwell\"\n",
    "        ),\n",
    "    )\n",
    "    '''\n",
    "\n",
    "    return labels, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff8a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, vals = visualize_distribution(bert_model, probs[0], 0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea52b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "ixxx = 0\n",
    "for prob in probs:\n",
    "    labels, vals = visualize_distribution(bert_model, prob, 0.015)\n",
    "    print(f'{labels} : {vals}')\n",
    "    ixxx += 1\n",
    "    if ixxx > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4070f4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bb6d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_topic_probability(topic_model, probabilities: np.ndarray, min_probability: float = 0.015):\n",
    "    \"\"\" Visualize the distribution of topic probabilities\n",
    "\n",
    "    Arguments:\n",
    "        topic_model: A fitted BERTopic instance\n",
    "        probabilities: An array of probability scores\n",
    "        min_probability: The minimum probability score to visualize.\n",
    "                         All others are ignored.\n",
    "    \"\"\"\n",
    "    \n",
    "    '''if len(probabilities[probabilities > min_probability]) == 0:\n",
    "        raise ValueError(\"There are no values where `min_probability` is higher than the \"\n",
    "                         \"probabilities that were supplied. Lower `min_probability` to prevent this error.\")'''\n",
    "    if not topic_model.calculate_probabilities:\n",
    "        raise ValueError(\"This visualization cannot be used if you have set `calculate_probabilities` to False \"\n",
    "                         \"as it uses the topic probabilities. \")\n",
    "\n",
    "    # Get values and indices equal or exceed the minimum probability\n",
    "    labels_idx = np.argwhere(probabilities >= min_probability).flatten()\n",
    "    vals = probabilities[labels_idx].tolist()\n",
    "\n",
    "    # Create labels\n",
    "    topics = []\n",
    "    for idx in labels_idx:\n",
    "        words = topic_model.get_topic(idx)\n",
    "        if words:\n",
    "            #label = [word[0] for word in words[:5]]\n",
    "            #label = f\"<b>Topic {idx}</b>: {'_'.join(label)}\"\n",
    "            #label = label[:40] + \"...\" if len(label) > 40 else label\n",
    "            #label = f'Topic {idx}'\n",
    "            topics.append(idx)\n",
    "        else:\n",
    "            vals.remove(probabilities[idx])\n",
    "\n",
    "    return topics, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7512c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_topic_probability1(probabilities: np.ndarray, min_probability: float = 0.015):\n",
    "    \"\"\" Visualize the distribution of topic probabilities\n",
    "\n",
    "    Arguments:\n",
    "        topic_model: A fitted BERTopic instance\n",
    "        probabilities: An array of probability scores\n",
    "        min_probability: The minimum probability score to visualize.\n",
    "                         All others are ignored.\n",
    "    \"\"\"\n",
    "    \n",
    "    '''if len(probabilities[probabilities > min_probability]) == 0:\n",
    "        raise ValueError(\"There are no values where `min_probability` is higher than the \"\n",
    "                         \"probabilities that were supplied. Lower `min_probability` to prevent this error.\")'''\n",
    "\n",
    "    # Get values and indices equal or exceed the minimum probability\n",
    "    labels_idx = np.argwhere(probabilities >= min_probability).flatten()\n",
    "    vals = probabilities[labels_idx].tolist()\n",
    "\n",
    "    # Create labels\n",
    "    topics = []\n",
    "    for idx in labels_idx:\n",
    "        #words = topic_model.get_topic(idx)\n",
    "        words = []\n",
    "        df_temp = topic_terms_df[topic_terms_df['topic'].str.match('0_')]\n",
    "        for _, row in df_temp.iterrows():\n",
    "            temp = (row['term'], row['weight'])\n",
    "            words.append(temp)\n",
    "        if words:\n",
    "            #label = [word[0] for word in words[:5]]\n",
    "            #label = f\"<b>Topic {idx}</b>: {'_'.join(label)}\"\n",
    "            #label = label[:40] + \"...\" if len(label) > 40 else label\n",
    "            #label = f'Topic {idx}'\n",
    "            topics.append(idx)\n",
    "        else:\n",
    "            vals.remove(probabilities[idx])\n",
    "\n",
    "    return topics, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1efcfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = []\n",
    "prob_list = []\n",
    "doc_id_list = []\n",
    "doc_id = 0\n",
    "for prob in probs:\n",
    "    topics, vals = get_doc_topic_probability(bert_model, prob, 0.00)\n",
    "    doc_topic = -1\n",
    "    doc_prob = 0\n",
    "    old_prob = 0\n",
    "    if len(topics) > 0:\n",
    "        for ind, topic in enumerate(topics):\n",
    "            #print(topic_probs)\n",
    "            if vals[ind] > old_prob:\n",
    "                doc_topic = topic\n",
    "                doc_prob = vals[ind]\n",
    "                old_prob = vals[ind]    \n",
    "    doc_id_list.append(doc_id) \n",
    "    topic_list.append(doc_topic)\n",
    "    prob_list.append(doc_prob)\n",
    "    doc_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ee02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc_topic_prob = pd.DataFrame(data={'document': doc_id_list, 'topic': topic_list, 'probabilities': prob_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6c4853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc_topic_prob[df_doc_topic_prob['topic']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07584c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ccca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = bert_model.get_topic(19)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9ee4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4249ccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_probability = 0.015\n",
    "min_probability = 0.001\n",
    "idx = 5682\n",
    "topics, vals = get_doc_topic_probability1(probs[idx], min_probability=min_probability)\n",
    "val_old = 0\n",
    "doc_topic = -1\n",
    "for ind, topic in enumerate(topics):\n",
    "    if vals[ind] > val_old:\n",
    "        doc_topic = topic\n",
    "        val_old = vals[ind]\n",
    "print(topics)\n",
    "print(vals)\n",
    "print(f'higher topic = {doc_topic}')\n",
    "print(f\"doc_topic = {docs_topic_df[docs_topic_df['document_id'] == idx]['topic'].to_list()[0]}\")\n",
    "bert_model.visualize_distribution(probs[idx], min_probability=min_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03166e1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "doc_topic_diff = []\n",
    "topic_not_found = []\n",
    "negative_topic = []\n",
    "topics_prob = []\n",
    "for i in range(0, 5683):\n",
    "    #min_probability = 0.001\n",
    "    min_probability = 0.0001\n",
    "    idx = i\n",
    "    topics, vals = get_doc_topic_probability1(probs[idx], min_probability=min_probability)\n",
    "    val_old = 0\n",
    "    doc_topic = -1\n",
    "    val = -1010\n",
    "    topic_prob = -2020\n",
    "    bert_doc_topic = docs_topic_df[docs_topic_df['document_id'] == idx]['topic'].to_list()[0]\n",
    "    \n",
    "    if bert_doc_topic >= 0:\n",
    "        for ind, topic in enumerate(topics):            \n",
    "            if vals[ind] > val_old:\n",
    "                doc_topic = topic\n",
    "                val = vals[ind]\n",
    "                val_old = vals[ind]\n",
    "            if bert_doc_topic == topic:\n",
    "                topic_prob = vals[ind]\n",
    "                topics_prob.append(topics_prob)\n",
    "                break\n",
    "        if (doc_topic != bert_doc_topic) and (topic_prob != -2020):\n",
    "            #print(topics)\n",
    "            #print(vals)        \n",
    "            doc_topic_diff.append(idx)\n",
    "            #print(f\"document {idx} topic {bert_doc_topic} probabilities {topic_prob} | higher topic = {doc_topic} probabilities {val}\")\n",
    "            #print(f'higher topic = {doc_topic}')\n",
    "            #print(f\"doc_topic = {docs_topic_df[docs_topic_df['document_id'] == idx]['topic'].to_list()[0]}\") \n",
    "    else:\n",
    "        if doc_topic == -1:\n",
    "            negative_topic.append(idx)\n",
    "            \n",
    "    if (topic_prob == -2020) and (bert_doc_topic != -1):\n",
    "        topic_not_found.append(idx)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e46129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 252\n",
    "# 1814\n",
    "print(len(doc_topic_diff))\n",
    "print(len(topic_not_found))\n",
    "print(len(topics_prob))\n",
    "print(len(topics_prob)+len(topic_not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dac7cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "251\n",
    "135\n",
    "3869\n",
    "4004"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
