{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8691738",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34710da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-20 19:00:52.755665: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from LeWagon_FinalProject.data import DataProcessor\n",
    "from bertopic import BERTopic\n",
    "import hdbscan\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6237b63",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8174f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_docs(df_, number_of_docs):\n",
    "    df_ = df_[['date', 'content']][0:number_of_docs].copy().reset_index(drop=True)\n",
    "    df_.to_csv(f'../raw_data/BERTDocsContent_{str(number_of_docs)}.csv', header=True, index=False, encoding='utf-8')\n",
    "    return df_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1221ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topic_info(bert_model, number_of_docs):\n",
    "    df_topic_info = bert_model.get_topic_info()\n",
    "\n",
    "    df_topic_info.to_csv(f'../raw_data/BERTopicInfo_{str(number_of_docs)}.csv', header=True, index=False, encoding='utf-8')\n",
    "    return df_topic_info.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734f46b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_terms(bert_model, number_of_docs):\n",
    "    topics = bert_model.get_topics()\n",
    "    number_of_topics = len(topics)-1    \n",
    "\n",
    "    topic_columns = ['topic', 'term', 'weight']\n",
    "\n",
    "    df_topics = pd.DataFrame(columns=topic_columns)\n",
    "    for i in range(-1,number_of_topics):\n",
    "        num_of_terms = len(topics[i])\n",
    "        for j in range(num_of_terms):\n",
    "            new_topic = {}\n",
    "            new_topic['topic'] = topic_model.topic_names[i]\n",
    "            new_topic['term'] = topics[i][j][0]\n",
    "            new_topic['weight'] = round(topics[i][j][1],6)\n",
    "            df_topics = df_topics.append(new_topic, ignore_index=True)\n",
    "\n",
    "    df_topics.to_csv(f'../raw_data/BERTopicTerms_{str(number_of_docs)}.csv', header=True, index=False, encoding='utf-8')\n",
    "    return df_topics.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2635dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix_to_df(df_corr):\n",
    "    list_done = []\n",
    "    lits_item1 = []\n",
    "    lits_item2 = []\n",
    "    list_corr = []\n",
    "\n",
    "    for k in range(1,df_corr.shape[1]):\n",
    "        for i, j in df_corr.iterrows():\n",
    "            #if (df_corr.columns[k] != j[0]) and (j[0] not in list_done):\n",
    "            #if (j[0] not in list_done):\n",
    "            lits_item1.append(df_corr.columns[k])\n",
    "            lits_item2.append(j[0])\n",
    "            list_corr.append(j[k])\n",
    "        list_done.append(df_corr.columns[k])\n",
    "\n",
    "    corr_dict = {'topic1': lits_item1,\n",
    "                 'topic2': lits_item2,\n",
    "                 'similarity': list_corr}\n",
    "    df_res = pd.DataFrame(corr_dict)\n",
    "    df_res = df_res.sort_values(by='similarity', ascending=False).copy()\n",
    "    df_res.reset_index(inplace=True,drop=True)\n",
    "    return df_res.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2304d11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topic_similarity(bert_model, number_of_docs):\n",
    "    corr_matrix = bert_model.topic_sim_matrix\n",
    "\n",
    "    topics = bert_model.get_topics()\n",
    "    number_of_topics = len(topics)-1\n",
    "\n",
    "    topic_columns = ['topic']\n",
    "    for i in range(-1,number_of_topics):\n",
    "        topic_columns.append(bert_model.topic_names[i])\n",
    "\n",
    "    df_similarity = pd.DataFrame(columns=topic_columns)\n",
    "    for i in range(-1,number_of_topics):\n",
    "        new_topic = {}\n",
    "        new_topic['topic'] = bert_model.topic_names[i]\n",
    "        for j in range(-1,number_of_topics):\n",
    "            new_topic[bert_model.topic_names[j]] = round(corr_matrix[i,j],6)\n",
    "        df_similarity = df_similarity.append(new_topic, ignore_index=True)\n",
    "        \n",
    "    df_topic_similarity = correlation_matrix_to_df(df_similarity)\n",
    "    df_topic_similarity.to_csv(f'../raw_data/BERTopicSimilarity_{str(number_of_docs)}.csv', header=True, index=False, encoding='utf-8')\n",
    "    return df_topic_similarity.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70084133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_documents(cluster_id, condensed_tree):\n",
    "    result_points = np.array([])\n",
    "    result_points_val = np.array([])\n",
    "    \n",
    "    #assert cluster_id > -1, \"The topic's label should be greater than -1!\"\n",
    "    \n",
    "    if cluster_id <= -1:\n",
    "        return result_points.astype(np.int64), result_points_val.astype(np.float64)\n",
    "        \n",
    "    raw_tree = condensed_tree._raw_tree\n",
    "    \n",
    "    # Just the cluster elements of the tree, excluding singleton points\n",
    "    cluster_tree = raw_tree[raw_tree['child_size'] > 1]\n",
    "    \n",
    "    # Get the leaf cluster nodes under the cluster we are considering\n",
    "    leaves = hdbscan.plots._recurse_leaf_dfs(cluster_tree, cluster_id)\n",
    "    \n",
    "    # Now collect up the last remaining points of each leaf cluster (the heart of the leaf) \n",
    "    for leaf in leaves:\n",
    "        #max_lambda = raw_tree['lambda_val'][raw_tree['parent'] == leaf].max()\n",
    "        #points = raw_tree['child'][(raw_tree['parent'] == leaf) & (raw_tree['lambda_val'] == max_lambda)]\n",
    "        #points_val = raw_tree['lambda_val'][(raw_tree['parent'] == leaf) & (raw_tree['lambda_val'] == max_lambda)]\n",
    "        points = raw_tree['child'][(raw_tree['parent'] == leaf)]\n",
    "        points_val = raw_tree['lambda_val'][(raw_tree['parent'] == leaf)]\n",
    "        result_points = np.hstack((result_points, points))\n",
    "        result_points_val = np.hstack((result_points_val, points_val))\n",
    "        \n",
    "    return result_points.astype(np.int64), result_points_val.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf25505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topic_documents(bert_model, number_of_docs):\n",
    "    clusterer = bert_model.hdbscan_model\n",
    "    tree = clusterer.condensed_tree_\n",
    "    clusters = tree._select_clusters()\n",
    "\n",
    "    number_of_topics = len(clusters)\n",
    "\n",
    "    relevant_columns = ['topic', 'document', 'lambda_val']\n",
    "    df_rel_docs = pd.DataFrame(columns=relevant_columns)\n",
    "        \n",
    "    if number_of_topics == len(bert_model.get_topics()):\n",
    "        start_ind = -1\n",
    "    else:\n",
    "        start_ind = 0\n",
    "\n",
    "    for i in range(0, number_of_topics):\n",
    "        rel_docs, lambda_vals = get_topic_documents(clusters[i], tree)\n",
    "        if len(rel_docs) > 0:\n",
    "            if start_ind < 0:\n",
    "                topic_name = bert_model.topic_names[i-1]\n",
    "            else:\n",
    "                topic_name = bert_model.topic_names[i]\n",
    "                \n",
    "            for j in range(0, len(rel_docs)):\n",
    "                new_doc_rel = {}\n",
    "                new_doc_rel['topic'] = topic_name\n",
    "                new_doc_rel['document'] = rel_docs[j]\n",
    "                new_doc_rel['lambda_val'] = round(lambda_vals[j],6)\n",
    "                df_rel_docs = df_rel_docs.append(new_doc_rel, ignore_index=True)\n",
    "\n",
    "    df_rel_docs.to_csv(f'../raw_data/BERTopicDocuments_{str(number_of_docs)}.csv', header=True, index=False, encoding='utf-8')\n",
    "    return df_rel_docs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def10c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(feature_vec_1, feature_vec_2):\n",
    "    return cosine_similarity(feature_vec_1.reshape(1, -1), feature_vec_2.reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a260c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_documents_similarity(bert_model, docs, number_of_docs):\n",
    "    emb_model = bert_model.embedding_model\n",
    "    \n",
    "    # Create documents embeddings\n",
    "    embeddings = emb_model.embedding_model.encode(docs)\n",
    "    doc_sim_matrix = cosine_similarity(embeddings, embeddings)\n",
    "    np.savetxt(f'../raw_data/BERTopicDocumentsSimilarity_{str(number_of_docs)}.csv', doc_sim_matrix, delimiter=',')\n",
    "    np.save(f'../raw_data/BERTopicDocumentsSimilarity_{str(number_of_docs)}.npy', doc_sim_matrix)\n",
    "    return doc_sim_matrix\n",
    "'''\n",
    "    sim_columns = ['cosine_similarity', 'document1', 'document2']\n",
    "    df_sim_docs = pd.DataFrame(columns=sim_columns)\n",
    "    temp_columns = ['cosine_similarity']\n",
    "    for i in range(0, len(docs)):\n",
    "        docs_sim = df_documents_similarity[i]\n",
    "        df_sim_docs_temp = pd.DataFrame(data = docs_sim, columns=temp_columns)\n",
    "        df_sim_docs_temp['document1'] = i\n",
    "        df_sim_docs_temp['document2'] = df_sim_docs_temp.index\n",
    "        df_sim_docs = df_sim_docs.append(df_sim_docs_temp, ignore_index=True)\n",
    "    \n",
    "    #df_sim_docs.to_csv(f'../raw_data/BERTopicDocumentsSimilarity_{str(number_of_docs)}.csv', header=True, index=False, encoding='utf-8')     \n",
    "    return df_sim_docs.copy()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1d13d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_start_end_dates(mode_index, topic_index):\n",
    "    df_topic = pd.read_csv(f'../raw_data/BERTopicInfo_{str(mode_index)}.csv')\n",
    "    topic_name = df_topic[df_topic['Topic']==topic_index]['Name'].values[0]\n",
    "\n",
    "    df_documents = pd.read_csv(f'../raw_data/BERTopicDocuments_{str(mode_index)}.csv')\n",
    "    df_documents = df_documents[df_documents['topic']==topic_name]\n",
    "\n",
    "    df_docscontent = pd.read_csv(f'../raw_data/BERTopicDocsContent_{str(mode_index)}.csv', parse_dates=True)\n",
    "    df_docscontent = df_docscontent[df_docscontent.index.isin(df_documents['document'].values)]\n",
    "    #start_date = df_docscontent['date'].min()\n",
    "    #end_date = df_docscontent['date'].max()\n",
    "    min_year = df_docscontent['year'].min()\n",
    "    min_month = df_docscontent[df_docscontent['year']==min_year]['month'].min()\n",
    "    \n",
    "    max_year = df_docscontent['year'].max()\n",
    "    max_month = df_docscontent[df_docscontent['year']==max_year]['month'].max()\n",
    "    \n",
    "    number_topic_docs = len(df_documents)\n",
    "    #return start_date, end_date, number_topic_docs\n",
    "    return min_year, min_month, max_year, max_month, topic_name, number_topic_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19af20e7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a641eb31",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''dp1 = DataProcessor(csv_path='../raw_data/', csv_name='articles1')\n",
    "df1 = dp1.load_dataset()\n",
    "\n",
    "dp2 = DataProcessor(csv_path='../raw_data/', csv_name='articles2')\n",
    "df2 = dp2.load_dataset()\n",
    "\n",
    "dp3 = DataProcessor(csv_path='../raw_data/', csv_name='articles3')\n",
    "df3 = dp3.load_dataset()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a97c90",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''df_all = df1.copy()\n",
    "df_all = df_all.append(df2, ignore_index=True)\n",
    "df_all = df_all.append(df3, ignore_index=True)\n",
    "df_all = df_all.sort_values(by=['year', 'month'], ascending=True).reset_index(drop=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c8560",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''print(df_all.shape)\n",
    "#df_all[(df_all['year'].isna())].dropna(inplace=True)\n",
    "df_all.dropna(subset=['year', 'month'], inplace=True)\n",
    "print(df_all.shape)\n",
    "df_all\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc77873",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''df_all = df_all[['id', 'title', 'year', 'month', 'content']].copy()\n",
    "df_all = df_all[df_all['year'] >= 2015].copy()\n",
    "df_all\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a67414",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#df_all.to_csv(f'../raw_data/dataset_work.csv', header=True, index=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee80cd4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''import requests\n",
    "url = 'https://bucketapipython-guadc7haza-uc.a.run.app/data'\n",
    "\n",
    "params = {'filename': 'dataset_work.csv', 'data': df_all.to_json()}\n",
    "\n",
    "x = requests.post(url, params=params)\n",
    "print(x.text)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba9f379",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''import requests\n",
    "url = 'https://bucketapipython-guadc7haza-uc.a.run.app/data'\n",
    "params = {'filename': 'dataset_work', 'extension': 'csv'}\n",
    "x = requests.get(url, params=params)\n",
    "x'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58fbbe35",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139514, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_docs = 3_000\n",
    "\n",
    "dp = DataProcessor(csv_path='../raw_data/', csv_name='dataset_work')\n",
    "df = dp.load_dataset()\n",
    "#df = df.sort_values(by='date', ascending=True).reset_index(drop=True)\n",
    "df = df.sort_values(by=['year', 'month'], ascending=True).reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a31cff2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "can_execute = False\n",
    "\n",
    "if can_execute:\n",
    "    number_of_docs = 3000\n",
    "    number_of_docs_back = 1500\n",
    "    number_of_iterations = df.shape[0]//number_of_docs\n",
    "\n",
    "    start_pos = 0\n",
    "    end_pos = number_of_docs-1\n",
    "    for i in range(0, number_of_iterations):\n",
    "        if i == (number_of_iterations-1):\n",
    "            if end_pos < (df.shape[0]-1):\n",
    "                end_pos += (df.shape[0]-1) - end_pos\n",
    "\n",
    "        if i > 0:\n",
    "            df_docs = df[(start_pos-number_of_docs_back):end_pos].sort_values(by=['year', 'month'], ascending=True).reset_index(drop=True)            \n",
    "        else:\n",
    "            df_docs = df[start_pos:end_pos].sort_values(by=['year', 'month'], ascending=True).reset_index(drop=True)\n",
    "\n",
    "        #if i > 12:    \n",
    "        docs = df_docs['content'].values\n",
    "        print('starting transform...')\n",
    "        topic_model = BERTopic(min_topic_size=30, language='english', calculate_probabilities=False, n_gram_range=(3,3))\n",
    "        topic_model.fit_transform(docs)\n",
    "        #print(len(topics))\n",
    "        #print(topics)\n",
    "        #break\n",
    "        topic_model.save('../raw_data/BERTopic_model_3_3_run_'+str(i))\n",
    "        print('end transform...')\n",
    "\n",
    "        df_docs.to_csv(f'../raw_data/BERTopicDocsContent_{str(i)}.csv', header=True, index=False, encoding='utf-8')\n",
    "\n",
    "        df_topics_info = generate_topic_info(topic_model, i)\n",
    "\n",
    "        df_terms = generate_terms(topic_model, i)\n",
    "\n",
    "        df_topic_similarity = generate_topic_similarity(topic_model, i)\n",
    "\n",
    "        df_topic_documents = generate_topic_documents(topic_model, i)\n",
    "\n",
    "        matrix_documents_similarity = generate_documents_similarity(topic_model, docs, i)\n",
    "\n",
    "        start_pos += number_of_docs\n",
    "        end_pos += number_of_docs\n",
    "\n",
    "        del docs\n",
    "        del df_docs\n",
    "        del df_topics_info\n",
    "        del df_terms\n",
    "        del df_topic_similarity\n",
    "        del df_topic_documents\n",
    "        del matrix_documents_similarity\n",
    "\n",
    "        print(f'done {str(i)} of {str(number_of_iterations-1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53985eee",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f926885",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Check term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5705582",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "number_of_iterations = 46\n",
    "\n",
    "models = []\n",
    "for i in range(0,number_of_iterations):\n",
    "    topic_model = BERTopic.load('../raw_data/BERTopic_model_3_3_run_'+str(i))\n",
    "    models.append(topic_model)\n",
    "    print(f'{i} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b40f5e3f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 10)\n",
      "CPU times: user 7min 59s, sys: 1min 32s, total: 9min 31s\n",
      "Wall time: 8min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "number_of_iterations = 46\n",
    "top_n_sim = 50\n",
    "search_terms = ['trump', 'climate change', 'biden', 'hillary']\n",
    "\n",
    "#term_similarity_columns = ['mode_index', 'bert_model', 'search_term', 'topic', 'topic_docs', 'topic_start_date', 'topic_end_date', 'similarity']\n",
    "term_similarity_columns = ['mode_index', 'bert_model', 'search_term', 'topic_name', 'topic_docs', 'topic_start_year', 'topic_start_month', 'topic_end_year', 'topic_end_month', 'similarity']\n",
    "df_term_similarity = pd.DataFrame(columns=term_similarity_columns)\n",
    "\n",
    "model_ind = 0\n",
    "#for topic_model in models:\n",
    "for i in range(0,number_of_iterations):\n",
    "    topic_model = BERTopic.load('../raw_data/BERTopic_model_3_3_run_'+str(i))\n",
    "    topic_ind = -1010\n",
    "    for search_term in search_terms:\n",
    "        similar_topics, similarity = topic_model.find_topics(search_term, top_n=top_n_sim)\n",
    "        if len(similar_topics) > 0:\n",
    "            for i in range(0,len(similar_topics)):\n",
    "                if similarity[i] < 0.7:\n",
    "                    break\n",
    "                if topic_ind != similar_topics[i]:\n",
    "                    #start_date, end_date, number_topic_docs = get_topic_start_end_dates(model_ind, similar_topics[i])\n",
    "                    min_year, min_month, max_year, max_month, topic_name, number_topic_docs = get_topic_start_end_dates(model_ind, similar_topics[i])\n",
    "                    topic_ind = similar_topics[i]\n",
    "                \n",
    "                new_term_sim = {}\n",
    "                new_term_sim['mode_index'] = model_ind\n",
    "                new_term_sim['bert_model'] = 'BERTopic_model_3_3_run_'+str(model_ind)\n",
    "                new_term_sim['search_term'] = search_term\n",
    "                new_term_sim['topic_name'] = topic_name\n",
    "                new_term_sim['topic_docs'] = number_topic_docs\n",
    "                #new_term_sim['topic_start_date'] = start_date\n",
    "                #new_term_sim['topic_end_date'] = end_date\n",
    "                \n",
    "                new_term_sim['topic_start_year'] = min_year\n",
    "                new_term_sim['topic_start_month'] = min_month\n",
    "                new_term_sim['topic_end_year'] = max_year\n",
    "                new_term_sim['topic_end_month'] = max_month\n",
    "                \n",
    "                new_term_sim['similarity'] = round(similarity[i],6)\n",
    "                df_term_similarity = df_term_similarity.append(new_term_sim, ignore_index=True)\n",
    "    model_ind += 1\n",
    "    del topic_model\n",
    "\n",
    "#df_term_similarity = df_term_similarity.sort_values(by=['search_term', 'topic_start_date'], ascending=True).reset_index(drop=True)\n",
    "df_term_similarity = df_term_similarity.sort_values(by=['search_term', 'topic_start_year', 'topic_start_month'], ascending=True).reset_index(drop=True)\n",
    "df_term_similarity.to_csv(f'../raw_data/BERTopicTermModelSimilarity.csv', header=True, index=False, encoding='utf-8')\n",
    "print(df_term_similarity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23bd623d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 10)\n"
     ]
    }
   ],
   "source": [
    "df_term_similarity = df_term_similarity.sort_values(by=['search_term', 'topic_start_year', 'topic_start_month'], ascending=True).reset_index(drop=True)\n",
    "df_term_similarity.to_csv(f'../raw_data/BERTopicTermModelSimilarity.csv', header=True, index=False, encoding='utf-8')\n",
    "print(df_term_similarity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56f11855",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode_index</th>\n",
       "      <th>bert_model</th>\n",
       "      <th>search_term</th>\n",
       "      <th>topic_name</th>\n",
       "      <th>topic_docs</th>\n",
       "      <th>topic_start_year</th>\n",
       "      <th>topic_start_month</th>\n",
       "      <th>topic_end_year</th>\n",
       "      <th>topic_end_month</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>BERTopic_model_3_3_run_8</td>\n",
       "      <td>climate change</td>\n",
       "      <td>15_sea level rise_the paris agreement_of clima...</td>\n",
       "      <td>116</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.777599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>BERTopic_model_3_3_run_9</td>\n",
       "      <td>climate change</td>\n",
       "      <td>16_clean power plan_of climate change_on clima...</td>\n",
       "      <td>33</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.907843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>BERTopic_model_3_3_run_10</td>\n",
       "      <td>climate change</td>\n",
       "      <td>19_the solar industry_the environmental protec...</td>\n",
       "      <td>33</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.717646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>BERTopic_model_3_3_run_11</td>\n",
       "      <td>climate change</td>\n",
       "      <td>7_the university of_great barrier reef_of clim...</td>\n",
       "      <td>42</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.716946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>BERTopic_model_3_3_run_24</td>\n",
       "      <td>climate change</td>\n",
       "      <td>21_the paris agreement_on climate change_the p...</td>\n",
       "      <td>94</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.863306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28</td>\n",
       "      <td>BERTopic_model_3_3_run_28</td>\n",
       "      <td>climate change</td>\n",
       "      <td>17_climate change is_environmental protection ...</td>\n",
       "      <td>67</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.858147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>BERTopic_model_3_3_run_30</td>\n",
       "      <td>climate change</td>\n",
       "      <td>26_of climate change_climate change and_on cli...</td>\n",
       "      <td>84</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.878410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31</td>\n",
       "      <td>BERTopic_model_3_3_run_31</td>\n",
       "      <td>climate change</td>\n",
       "      <td>20_environmental protection agency_of climate ...</td>\n",
       "      <td>198</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.771006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>BERTopic_model_3_3_run_32</td>\n",
       "      <td>climate change</td>\n",
       "      <td>19_on climate change_environmental protection ...</td>\n",
       "      <td>250</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.929588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39</td>\n",
       "      <td>BERTopic_model_3_3_run_39</td>\n",
       "      <td>climate change</td>\n",
       "      <td>12_daylight saving time_march for science_clea...</td>\n",
       "      <td>41</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.848293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41</td>\n",
       "      <td>BERTopic_model_3_3_run_41</td>\n",
       "      <td>climate change</td>\n",
       "      <td>11_march for science_the march for_climate cha...</td>\n",
       "      <td>36</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.782616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>42</td>\n",
       "      <td>BERTopic_model_3_3_run_42</td>\n",
       "      <td>climate change</td>\n",
       "      <td>10_the paris agreement_the paris climate_march...</td>\n",
       "      <td>60</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.838176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>43</td>\n",
       "      <td>BERTopic_model_3_3_run_43</td>\n",
       "      <td>climate change</td>\n",
       "      <td>20_the paris agreement_on climate change_the p...</td>\n",
       "      <td>63</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.726458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>BERTopic_model_3_3_run_7</td>\n",
       "      <td>hillary</td>\n",
       "      <td>2_secretary of state_former secretary of_hilla...</td>\n",
       "      <td>147</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.756745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>BERTopic_model_3_3_run_10</td>\n",
       "      <td>hillary</td>\n",
       "      <td>5_former president bill_the white house_presid...</td>\n",
       "      <td>43</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.724135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11</td>\n",
       "      <td>BERTopic_model_3_3_run_11</td>\n",
       "      <td>hillary</td>\n",
       "      <td>8_secretary of state_mrs clinton said_mrs clin...</td>\n",
       "      <td>32</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.814758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12</td>\n",
       "      <td>BERTopic_model_3_3_run_12</td>\n",
       "      <td>hillary</td>\n",
       "      <td>4_secretary of state_mrs clinton said_as secre...</td>\n",
       "      <td>269</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.795362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14</td>\n",
       "      <td>BERTopic_model_3_3_run_14</td>\n",
       "      <td>hillary</td>\n",
       "      <td>6_democratic national convention_the democrati...</td>\n",
       "      <td>39</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.723814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>BERTopic_model_3_3_run_17</td>\n",
       "      <td>hillary</td>\n",
       "      <td>12_democratic presidential nominee_nominee hil...</td>\n",
       "      <td>49</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.800249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22</td>\n",
       "      <td>BERTopic_model_3_3_run_22</td>\n",
       "      <td>hillary</td>\n",
       "      <td>5_secretary of state_democratic presidential n...</td>\n",
       "      <td>91</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.812811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>36</td>\n",
       "      <td>BERTopic_model_3_3_run_36</td>\n",
       "      <td>hillary</td>\n",
       "      <td>14_mrs clinton has_mrs clinton said_for mrs cl...</td>\n",
       "      <td>36</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.822134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>39</td>\n",
       "      <td>BERTopic_model_3_3_run_39</td>\n",
       "      <td>hillary</td>\n",
       "      <td>21_mrs clinton said_mrs clinton and_of the dem...</td>\n",
       "      <td>37</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.793776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12</td>\n",
       "      <td>BERTopic_model_3_3_run_12</td>\n",
       "      <td>trump</td>\n",
       "      <td>20_the trump organization_the trump campaign_t...</td>\n",
       "      <td>35</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.944085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>BERTopic_model_3_3_run_12</td>\n",
       "      <td>trump</td>\n",
       "      <td>23_im building wall_the trump university_mr tr...</td>\n",
       "      <td>49</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.774017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>14</td>\n",
       "      <td>BERTopic_model_3_3_run_14</td>\n",
       "      <td>trump</td>\n",
       "      <td>1_the republican national_republican national ...</td>\n",
       "      <td>35</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.754474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17</td>\n",
       "      <td>BERTopic_model_3_3_run_17</td>\n",
       "      <td>trump</td>\n",
       "      <td>7_that donald trump_donald trump is_mr trump h...</td>\n",
       "      <td>69</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.942527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>21</td>\n",
       "      <td>BERTopic_model_3_3_run_21</td>\n",
       "      <td>trump</td>\n",
       "      <td>0_the white house_the trump campaign_the new y...</td>\n",
       "      <td>127</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.723367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>22</td>\n",
       "      <td>BERTopic_model_3_3_run_22</td>\n",
       "      <td>trump</td>\n",
       "      <td>13_vice presidential debate_gov mike pence_don...</td>\n",
       "      <td>204</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.717595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>24</td>\n",
       "      <td>BERTopic_model_3_3_run_24</td>\n",
       "      <td>trump</td>\n",
       "      <td>2_the wall day_donald trump is_the new york_no...</td>\n",
       "      <td>45</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.864859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>26</td>\n",
       "      <td>BERTopic_model_3_3_run_26</td>\n",
       "      <td>trump</td>\n",
       "      <td>4_the white house_the popular vote_the new yor...</td>\n",
       "      <td>116</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.725784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>26</td>\n",
       "      <td>BERTopic_model_3_3_run_26</td>\n",
       "      <td>trump</td>\n",
       "      <td>16_conflicts of interest_the trump organizatio...</td>\n",
       "      <td>191</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.711896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>27</td>\n",
       "      <td>BERTopic_model_3_3_run_27</td>\n",
       "      <td>trump</td>\n",
       "      <td>9_the trump organization_conflicts of interest...</td>\n",
       "      <td>34</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.736914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>29</td>\n",
       "      <td>BERTopic_model_3_3_run_29</td>\n",
       "      <td>trump</td>\n",
       "      <td>4_of mr trumps_mr trump has_mr trump said_that...</td>\n",
       "      <td>82</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>29</td>\n",
       "      <td>BERTopic_model_3_3_run_29</td>\n",
       "      <td>trump</td>\n",
       "      <td>11_conflicts of interest_the trump organizatio...</td>\n",
       "      <td>69</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.719375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>BERTopic_model_3_3_run_35</td>\n",
       "      <td>trump</td>\n",
       "      <td>28_trump and abe_minister shinzo abe_the trump...</td>\n",
       "      <td>98</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.710460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>BERTopic_model_3_3_run_36</td>\n",
       "      <td>trump</td>\n",
       "      <td>5_the white house_the trump organization_trump...</td>\n",
       "      <td>39</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.795481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>BERTopic_model_3_3_run_37</td>\n",
       "      <td>trump</td>\n",
       "      <td>5_the trump organization_the white house_table...</td>\n",
       "      <td>89</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.811651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>40</td>\n",
       "      <td>BERTopic_model_3_3_run_40</td>\n",
       "      <td>trump</td>\n",
       "      <td>8_first 100 days_the white house_the trump org...</td>\n",
       "      <td>77</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.707991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>42</td>\n",
       "      <td>BERTopic_model_3_3_run_42</td>\n",
       "      <td>trump</td>\n",
       "      <td>4_the white house_his first 100_president dona...</td>\n",
       "      <td>66</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.738419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5</td>\n",
       "      <td>BERTopic_model_3_3_run_5</td>\n",
       "      <td>trump</td>\n",
       "      <td>-1_the republican party_sen ted cruz_donald tr...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>19</td>\n",
       "      <td>BERTopic_model_3_3_run_19</td>\n",
       "      <td>trump</td>\n",
       "      <td>-1_nominee donald trump_donald trump is_the ne...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.767205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mode_index                 bert_model     search_term  \\\n",
       "0           8   BERTopic_model_3_3_run_8  climate change   \n",
       "1           9   BERTopic_model_3_3_run_9  climate change   \n",
       "2          10  BERTopic_model_3_3_run_10  climate change   \n",
       "3          11  BERTopic_model_3_3_run_11  climate change   \n",
       "4          24  BERTopic_model_3_3_run_24  climate change   \n",
       "5          28  BERTopic_model_3_3_run_28  climate change   \n",
       "6          30  BERTopic_model_3_3_run_30  climate change   \n",
       "7          31  BERTopic_model_3_3_run_31  climate change   \n",
       "8          32  BERTopic_model_3_3_run_32  climate change   \n",
       "9          39  BERTopic_model_3_3_run_39  climate change   \n",
       "10         41  BERTopic_model_3_3_run_41  climate change   \n",
       "11         42  BERTopic_model_3_3_run_42  climate change   \n",
       "12         43  BERTopic_model_3_3_run_43  climate change   \n",
       "13          7   BERTopic_model_3_3_run_7         hillary   \n",
       "14         10  BERTopic_model_3_3_run_10         hillary   \n",
       "15         11  BERTopic_model_3_3_run_11         hillary   \n",
       "16         12  BERTopic_model_3_3_run_12         hillary   \n",
       "17         14  BERTopic_model_3_3_run_14         hillary   \n",
       "18         17  BERTopic_model_3_3_run_17         hillary   \n",
       "19         22  BERTopic_model_3_3_run_22         hillary   \n",
       "20         36  BERTopic_model_3_3_run_36         hillary   \n",
       "21         39  BERTopic_model_3_3_run_39         hillary   \n",
       "22         12  BERTopic_model_3_3_run_12           trump   \n",
       "23         12  BERTopic_model_3_3_run_12           trump   \n",
       "24         14  BERTopic_model_3_3_run_14           trump   \n",
       "25         17  BERTopic_model_3_3_run_17           trump   \n",
       "26         21  BERTopic_model_3_3_run_21           trump   \n",
       "27         22  BERTopic_model_3_3_run_22           trump   \n",
       "28         24  BERTopic_model_3_3_run_24           trump   \n",
       "29         26  BERTopic_model_3_3_run_26           trump   \n",
       "30         26  BERTopic_model_3_3_run_26           trump   \n",
       "31         27  BERTopic_model_3_3_run_27           trump   \n",
       "32         29  BERTopic_model_3_3_run_29           trump   \n",
       "33         29  BERTopic_model_3_3_run_29           trump   \n",
       "34         35  BERTopic_model_3_3_run_35           trump   \n",
       "35         36  BERTopic_model_3_3_run_36           trump   \n",
       "36         37  BERTopic_model_3_3_run_37           trump   \n",
       "37         40  BERTopic_model_3_3_run_40           trump   \n",
       "38         42  BERTopic_model_3_3_run_42           trump   \n",
       "39          5   BERTopic_model_3_3_run_5           trump   \n",
       "40         19  BERTopic_model_3_3_run_19           trump   \n",
       "\n",
       "                                           topic_name topic_docs  \\\n",
       "0   15_sea level rise_the paris agreement_of clima...        116   \n",
       "1   16_clean power plan_of climate change_on clima...         33   \n",
       "2   19_the solar industry_the environmental protec...         33   \n",
       "3   7_the university of_great barrier reef_of clim...         42   \n",
       "4   21_the paris agreement_on climate change_the p...         94   \n",
       "5   17_climate change is_environmental protection ...         67   \n",
       "6   26_of climate change_climate change and_on cli...         84   \n",
       "7   20_environmental protection agency_of climate ...        198   \n",
       "8   19_on climate change_environmental protection ...        250   \n",
       "9   12_daylight saving time_march for science_clea...         41   \n",
       "10  11_march for science_the march for_climate cha...         36   \n",
       "11  10_the paris agreement_the paris climate_march...         60   \n",
       "12  20_the paris agreement_on climate change_the p...         63   \n",
       "13  2_secretary of state_former secretary of_hilla...        147   \n",
       "14  5_former president bill_the white house_presid...         43   \n",
       "15  8_secretary of state_mrs clinton said_mrs clin...         32   \n",
       "16  4_secretary of state_mrs clinton said_as secre...        269   \n",
       "17  6_democratic national convention_the democrati...         39   \n",
       "18  12_democratic presidential nominee_nominee hil...         49   \n",
       "19  5_secretary of state_democratic presidential n...         91   \n",
       "20  14_mrs clinton has_mrs clinton said_for mrs cl...         36   \n",
       "21  21_mrs clinton said_mrs clinton and_of the dem...         37   \n",
       "22  20_the trump organization_the trump campaign_t...         35   \n",
       "23  23_im building wall_the trump university_mr tr...         49   \n",
       "24  1_the republican national_republican national ...         35   \n",
       "25  7_that donald trump_donald trump is_mr trump h...         69   \n",
       "26  0_the white house_the trump campaign_the new y...        127   \n",
       "27  13_vice presidential debate_gov mike pence_don...        204   \n",
       "28  2_the wall day_donald trump is_the new york_no...         45   \n",
       "29  4_the white house_the popular vote_the new yor...        116   \n",
       "30  16_conflicts of interest_the trump organizatio...        191   \n",
       "31  9_the trump organization_conflicts of interest...         34   \n",
       "32  4_of mr trumps_mr trump has_mr trump said_that...         82   \n",
       "33  11_conflicts of interest_the trump organizatio...         69   \n",
       "34  28_trump and abe_minister shinzo abe_the trump...         98   \n",
       "35  5_the white house_the trump organization_trump...         39   \n",
       "36  5_the trump organization_the white house_table...         89   \n",
       "37  8_first 100 days_the white house_the trump org...         77   \n",
       "38  4_the white house_his first 100_president dona...         66   \n",
       "39  -1_the republican party_sen ted cruz_donald tr...          0   \n",
       "40  -1_nominee donald trump_donald trump is_the ne...          0   \n",
       "\n",
       "    topic_start_year  topic_start_month  topic_end_year  topic_end_month  \\\n",
       "0             2016.0                3.0          2016.0              4.0   \n",
       "1             2016.0                4.0          2016.0              5.0   \n",
       "2             2016.0                4.0          2016.0              5.0   \n",
       "3             2016.0                5.0          2016.0              6.0   \n",
       "4             2016.0               10.0          2016.0             11.0   \n",
       "5             2016.0               12.0          2016.0             12.0   \n",
       "6             2016.0               12.0          2017.0              1.0   \n",
       "7             2017.0                1.0          2017.0              1.0   \n",
       "8             2017.0                1.0          2017.0              2.0   \n",
       "9             2017.0                3.0          2017.0              4.0   \n",
       "10            2017.0                4.0          2017.0              4.0   \n",
       "11            2017.0                4.0          2017.0              5.0   \n",
       "12            2017.0                5.0          2017.0              5.0   \n",
       "13            2016.0                3.0          2016.0              4.0   \n",
       "14            2016.0                4.0          2016.0              5.0   \n",
       "15            2016.0                5.0          2016.0              6.0   \n",
       "16            2016.0                5.0          2016.0              6.0   \n",
       "17            2016.0                6.0          2016.0              7.0   \n",
       "18            2016.0                7.0          2016.0              8.0   \n",
       "19            2016.0                9.0          2016.0             10.0   \n",
       "20            2017.0                2.0          2017.0              3.0   \n",
       "21            2017.0                3.0          2017.0              4.0   \n",
       "22            2016.0                5.0          2016.0              6.0   \n",
       "23            2016.0                5.0          2016.0              6.0   \n",
       "24            2016.0                6.0          2016.0              7.0   \n",
       "25            2016.0                8.0          2016.0              8.0   \n",
       "26            2016.0                9.0          2016.0             10.0   \n",
       "27            2016.0                9.0          2016.0             10.0   \n",
       "28            2016.0               10.0          2016.0             11.0   \n",
       "29            2016.0               11.0          2016.0             11.0   \n",
       "30            2016.0               11.0          2016.0             11.0   \n",
       "31            2016.0               11.0          2016.0             12.0   \n",
       "32            2016.0               12.0          2017.0              1.0   \n",
       "33            2016.0               12.0          2017.0              1.0   \n",
       "34            2017.0                2.0          2017.0              3.0   \n",
       "35            2017.0                2.0          2017.0              3.0   \n",
       "36            2017.0                3.0          2017.0              3.0   \n",
       "37            2017.0                4.0          2017.0              4.0   \n",
       "38            2017.0                4.0          2017.0              5.0   \n",
       "39               NaN                NaN             NaN              NaN   \n",
       "40               NaN                NaN             NaN              NaN   \n",
       "\n",
       "    similarity  \n",
       "0     0.777599  \n",
       "1     0.907843  \n",
       "2     0.717646  \n",
       "3     0.716946  \n",
       "4     0.863306  \n",
       "5     0.858147  \n",
       "6     0.878410  \n",
       "7     0.771006  \n",
       "8     0.929588  \n",
       "9     0.848293  \n",
       "10    0.782616  \n",
       "11    0.838176  \n",
       "12    0.726458  \n",
       "13    0.756745  \n",
       "14    0.724135  \n",
       "15    0.814758  \n",
       "16    0.795362  \n",
       "17    0.723814  \n",
       "18    0.800249  \n",
       "19    0.812811  \n",
       "20    0.822134  \n",
       "21    0.793776  \n",
       "22    0.944085  \n",
       "23    0.774017  \n",
       "24    0.754474  \n",
       "25    0.942527  \n",
       "26    0.723367  \n",
       "27    0.717595  \n",
       "28    0.864859  \n",
       "29    0.725784  \n",
       "30    0.711896  \n",
       "31    0.736914  \n",
       "32    0.898739  \n",
       "33    0.719375  \n",
       "34    0.710460  \n",
       "35    0.795481  \n",
       "36    0.811651  \n",
       "37    0.707991  \n",
       "38    0.738419  \n",
       "39    0.785396  \n",
       "40    0.767205  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_term_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d46757",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# search_terms = ['trump', 'climate change', 'biden', 'hillary']\n",
    "df_term_similarity[df_term_similarity['search_term']=='climate change']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01f02f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parei aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f293322",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Validate n_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd3261f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dp = DataProcessor(csv_path='../raw_data/', csv_name='dataset_work')\n",
    "df = dp.load_dataset()\n",
    "df = df.sort_values(by=['year', 'month'], ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd2e85b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_ = df[df['year'] == 2015].copy()\n",
    "print(df_.shape)\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ea2b59",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_grams = []\n",
    "\n",
    "n_grams.append((1,1))\n",
    "n_grams.append((1,2))\n",
    "n_grams.append((1,3))\n",
    "n_grams.append((1,4))\n",
    "n_grams.append((1,5))\n",
    "n_grams.append((1,6))\n",
    "n_grams.append((1,7))\n",
    "n_grams.append((1,8))\n",
    "n_grams.append((1,9))\n",
    "\n",
    "n_grams.append((2,2))\n",
    "n_grams.append((2,3))\n",
    "n_grams.append((2,4))\n",
    "n_grams.append((2,5))\n",
    "n_grams.append((2,6))\n",
    "n_grams.append((2,7))\n",
    "n_grams.append((2,8))\n",
    "n_grams.append((2,9))\n",
    "\n",
    "n_grams.append((3,3))\n",
    "n_grams.append((3,4))\n",
    "n_grams.append((3,5))\n",
    "n_grams.append((3,6))\n",
    "n_grams.append((3,7))\n",
    "n_grams.append((3,8))\n",
    "n_grams.append((3,9))\n",
    "\n",
    "n_grams.append((4,4))\n",
    "n_grams.append((4,5))\n",
    "n_grams.append((4,6))\n",
    "n_grams.append((4,7))\n",
    "n_grams.append((4,8))\n",
    "n_grams.append((4,9))\n",
    "\n",
    "n_grams.append((5,5))\n",
    "n_grams.append((5,6))\n",
    "n_grams.append((5,7))\n",
    "n_grams.append((5,8))\n",
    "n_grams.append((5,9))\n",
    "\n",
    "n_grams.append((6,6))\n",
    "n_grams.append((6,7))\n",
    "n_grams.append((6,8))\n",
    "n_grams.append((6,9))\n",
    "\n",
    "n_grams.append((7,7))\n",
    "n_grams.append((7,8))\n",
    "n_grams.append((7,9))\n",
    "\n",
    "n_grams.append((8,8))\n",
    "n_grams.append((8,9))\n",
    "\n",
    "n_grams.append((9,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bcac4f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "can_execute = False\n",
    "if can_execute:    \n",
    "    for n_gram in n_grams:\n",
    "        n_gram_txt = f'{str(n_gram[0])}_{str(n_gram[1])}'\n",
    "\n",
    "        df_docs = df_.sort_values(by=['year', 'month'], ascending=True).reset_index(drop=True)\n",
    "        docs = df_docs['content'].values\n",
    "        print('starting transform...')\n",
    "        topic_model = BERTopic(min_topic_size=30, language='english', calculate_probabilities=False, n_gram_range=n_gram)\n",
    "        topic_model.fit_transform(docs)\n",
    "\n",
    "        topic_model.save('../raw_data/BERTopic_model_'+str(n_gram_txt))\n",
    "        print('end transform...')\n",
    "\n",
    "        df_docs.to_csv(f'../raw_data/BERTopicDocsContent_{n_gram_txt}.csv', header=True, index=False, encoding='utf-8')\n",
    "\n",
    "        df_topics_info = generate_topic_info(topic_model, n_gram_txt)\n",
    "\n",
    "        df_terms = generate_terms(topic_model, n_gram_txt)\n",
    "\n",
    "        del topic_model\n",
    "        del docs\n",
    "        del df_docs\n",
    "        del df_topics_info\n",
    "        del df_terms\n",
    "\n",
    "        print(f'done n_gram: {n_gram_txt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5312610e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "can_execute = False\n",
    "if can_execute:\n",
    "    icount = 0\n",
    "    for n_gram in n_grams:         \n",
    "        n_gram_txt = f'{str(n_gram[0])}_{str(n_gram[1])}'\n",
    "        df_topic_info = pd.read_csv(f'../raw_data/BERTopicInfo_{n_gram_txt}.csv')\n",
    "        df_topic_info = df_topic_info.head(1).copy()\n",
    "        df_topic_info['n_gram'] = n_gram_txt\n",
    "        if icount == 0:\n",
    "            df_topic_nones = df_topic_info.copy()\n",
    "        else:\n",
    "            df_topic_nones = df_topic_nones.append(df_topic_info, ignore_index=True)\n",
    "\n",
    "        del df_topic_info\n",
    "        icount += 1\n",
    "\n",
    "    df_topic_nones.to_csv('../raw_data/validate_n_gram/BERTopicResult_n_gram.csv', header=True, index=False, encoding='utf-8')\n",
    "    df_topic_nones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa6c75f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>n_gram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1403</td>\n",
       "      <td>-1_the united states_the white house_in the un...</td>\n",
       "      <td>3_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>1409</td>\n",
       "      <td>-1_follow us on twitter cnnopinion join_follow...</td>\n",
       "      <td>6_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>1419</td>\n",
       "      <td>-1_follow us on twitter cnnopinion_twitter cnn...</td>\n",
       "      <td>5_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>1434</td>\n",
       "      <td>-1_the white house_us on facebook_join us on_j...</td>\n",
       "      <td>3_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>1442</td>\n",
       "      <td>-1_follow us on twitter cnnopinion_us on twitt...</td>\n",
       "      <td>4_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1</td>\n",
       "      <td>1442</td>\n",
       "      <td>-1_on twitter cnnopinion join us on_us on twit...</td>\n",
       "      <td>5_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1</td>\n",
       "      <td>1443</td>\n",
       "      <td>-1_us on twitter cnnopinion join us_follow us ...</td>\n",
       "      <td>4_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1</td>\n",
       "      <td>1447</td>\n",
       "      <td>-1_follow us on twitter cnnopinion join_on twi...</td>\n",
       "      <td>6_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1</td>\n",
       "      <td>1447</td>\n",
       "      <td>-1_follow us on twitter cnnopinion_us on twitt...</td>\n",
       "      <td>5_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1</td>\n",
       "      <td>1458</td>\n",
       "      <td>-1_follow us on twitter cnnopinion join us_us ...</td>\n",
       "      <td>7_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1</td>\n",
       "      <td>1472</td>\n",
       "      <td>-1_us on twitter cnnopinion join us on_follow ...</td>\n",
       "      <td>7_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1</td>\n",
       "      <td>1472</td>\n",
       "      <td>-1_of the_to the_and the_with the</td>\n",
       "      <td>2_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1</td>\n",
       "      <td>1475</td>\n",
       "      <td>-1_in_on_with_he</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1</td>\n",
       "      <td>1476</td>\n",
       "      <td>-1_on twitter cnnopinion join us_us on twitter...</td>\n",
       "      <td>4_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1</td>\n",
       "      <td>1498</td>\n",
       "      <td>-1_us on twitter cnnopinion join us on_on twit...</td>\n",
       "      <td>6_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1</td>\n",
       "      <td>1504</td>\n",
       "      <td>-1_to_in_on_he</td>\n",
       "      <td>1_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1</td>\n",
       "      <td>1516</td>\n",
       "      <td>-1_of the_in the_to the_and the</td>\n",
       "      <td>2_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1</td>\n",
       "      <td>1522</td>\n",
       "      <td>-1_the united states_in the united_in the unit...</td>\n",
       "      <td>3_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1</td>\n",
       "      <td>1551</td>\n",
       "      <td>-1_follow us on twitter cnnopinion join us on ...</td>\n",
       "      <td>9_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1</td>\n",
       "      <td>1570</td>\n",
       "      <td>-1_of_on_with_he</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1</td>\n",
       "      <td>1580</td>\n",
       "      <td>-1_of the_in the_to the_on the</td>\n",
       "      <td>2_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1</td>\n",
       "      <td>1624</td>\n",
       "      <td>-1_follow us on twitter cnnopinion_follow us o...</td>\n",
       "      <td>5_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1</td>\n",
       "      <td>3642</td>\n",
       "      <td>-1_follow us on twitter cnnopinion join us on_...</td>\n",
       "      <td>8_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_the_to_of_in</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_us on twitter cnnopinion join us on_follow ...</td>\n",
       "      <td>7_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_the_to_of_in</td>\n",
       "      <td>1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_the_to_of_in</td>\n",
       "      <td>1_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_follow us on twitter cnnopinion join us_us ...</td>\n",
       "      <td>6_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_the_to_of_in</td>\n",
       "      <td>1_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_the_to_of_in</td>\n",
       "      <td>1_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_us on twitter cnnopinion join us_follow us ...</td>\n",
       "      <td>5_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_the united states_the white house_in the un...</td>\n",
       "      <td>3_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_of the_in the_to the_to be</td>\n",
       "      <td>2_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_us on twitter cnnopinion join us_on twitter...</td>\n",
       "      <td>4_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_of the_in the_to the_to be</td>\n",
       "      <td>2_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_follow us on twitter cnnopinion_follow us o...</td>\n",
       "      <td>4_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_of the_in the_to the_to be</td>\n",
       "      <td>2_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_of the_in the_to the_to be</td>\n",
       "      <td>2_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_follow us on twitter cnnopinion join us on_...</td>\n",
       "      <td>8_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_the united states_the white house_in the un...</td>\n",
       "      <td>3_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_the united states_the white house_in the un...</td>\n",
       "      <td>3_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_the united states_the white house_in the un...</td>\n",
       "      <td>3_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-1</td>\n",
       "      <td>3643</td>\n",
       "      <td>-1_the_of_in_with</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-1</td>\n",
       "      <td>3644</td>\n",
       "      <td>-1_of the_in the_to the_to be</td>\n",
       "      <td>2_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-1</td>\n",
       "      <td>3661</td>\n",
       "      <td>-1_us on twitter cnnopinion_cnnopinion join us...</td>\n",
       "      <td>4_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                               Name n_gram\n",
       "0      -1   1403  -1_the united states_the white house_in the un...    3_3\n",
       "1      -1   1409  -1_follow us on twitter cnnopinion join_follow...    6_9\n",
       "2      -1   1419  -1_follow us on twitter cnnopinion_twitter cnn...    5_5\n",
       "3      -1   1434  -1_the white house_us on facebook_join us on_j...    3_8\n",
       "4      -1   1442  -1_follow us on twitter cnnopinion_us on twitt...    4_5\n",
       "5      -1   1442  -1_on twitter cnnopinion join us on_us on twit...    5_9\n",
       "6      -1   1443  -1_us on twitter cnnopinion join us_follow us ...    4_8\n",
       "7      -1   1447  -1_follow us on twitter cnnopinion join_on twi...    6_6\n",
       "8      -1   1447  -1_follow us on twitter cnnopinion_us on twitt...    5_6\n",
       "9      -1   1458  -1_follow us on twitter cnnopinion join us_us ...    7_7\n",
       "10     -1   1472  -1_us on twitter cnnopinion join us on_follow ...    7_9\n",
       "11     -1   1472                  -1_of the_to the_and the_with the    2_8\n",
       "12     -1   1475                                   -1_in_on_with_he    1_3\n",
       "13     -1   1476  -1_on twitter cnnopinion join us_us on twitter...    4_7\n",
       "14     -1   1498  -1_us on twitter cnnopinion join us on_on twit...    6_8\n",
       "15     -1   1504                                     -1_to_in_on_he    1_7\n",
       "16     -1   1516                    -1_of the_in the_to the_and the    2_2\n",
       "17     -1   1522  -1_the united states_in the united_in the unit...    3_9\n",
       "18     -1   1551  -1_follow us on twitter cnnopinion join us on ...    9_9\n",
       "19     -1   1570                                   -1_of_on_with_he    1_4\n",
       "20     -1   1580                     -1_of the_in the_to the_on the    2_3\n",
       "21     -1   1624  -1_follow us on twitter cnnopinion_follow us o...    5_7\n",
       "22     -1   3642  -1_follow us on twitter cnnopinion join us on_...    8_8\n",
       "23     -1   3643                                    -1_the_to_of_in    1_2\n",
       "24     -1   3643  -1_us on twitter cnnopinion join us on_follow ...    7_8\n",
       "25     -1   3643                                    -1_the_to_of_in    1_5\n",
       "26     -1   3643                                    -1_the_to_of_in    1_6\n",
       "27     -1   3643  -1_follow us on twitter cnnopinion join us_us ...    6_7\n",
       "28     -1   3643                                    -1_the_to_of_in    1_8\n",
       "29     -1   3643                                    -1_the_to_of_in    1_9\n",
       "30     -1   3643  -1_us on twitter cnnopinion join us_follow us ...    5_8\n",
       "31     -1   3643  -1_the united states_the white house_in the un...    3_5\n",
       "32     -1   3643                      -1_of the_in the_to the_to be    2_4\n",
       "33     -1   3643  -1_us on twitter cnnopinion join us_on twitter...    4_9\n",
       "34     -1   3643                      -1_of the_in the_to the_to be    2_5\n",
       "35     -1   3643  -1_follow us on twitter cnnopinion_follow us o...    4_6\n",
       "36     -1   3643                      -1_of the_in the_to the_to be    2_7\n",
       "37     -1   3643                      -1_of the_in the_to the_to be    2_9\n",
       "38     -1   3643  -1_follow us on twitter cnnopinion join us on_...    8_9\n",
       "39     -1   3643  -1_the united states_the white house_in the un...    3_7\n",
       "40     -1   3643  -1_the united states_the white house_in the un...    3_6\n",
       "41     -1   3643  -1_the united states_the white house_in the un...    3_4\n",
       "42     -1   3643                                  -1_the_of_in_with    1_1\n",
       "43     -1   3644                      -1_of the_in the_to the_to be    2_6\n",
       "44     -1   3661  -1_us on twitter cnnopinion_cnnopinion join us...    4_4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_nones = pd.read_csv('../raw_data/validate_n_gram/BERTopicResult_n_gram.csv')\n",
    "df_topic_nones.sort_values(by=['Count'], ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b92fda0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42168b42",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_term_model_sim = pd.read_csv('../raw_data/BERTopicTermModelSimilarity.csv')\n",
    "#df_topic_nones.sort_values(by=['Count'], ascending=True).reset_index(drop=True)\n",
    "#df_term_model_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f329cf90",
   "metadata": {},
   "source": [
    "## Generate political dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b191ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "political_words = ['hillary',\n",
    "         'clinton',\n",
    "         'trump',\n",
    "         'donald'\n",
    "         'barack',\n",
    "         'obama',\n",
    "         'election',\n",
    "         'democracy',\n",
    "         'democrats',\n",
    "         'republicans',\n",
    "         'president',\n",
    "         'candidate',\n",
    "         'elector',\n",
    "         'vote',\n",
    "         'voting',\n",
    "         'voter',\n",
    "         'elector',\n",
    "         'government',\n",
    "         'big government',\n",
    "         'bipartisan',\n",
    "         'bleeding heart',\n",
    "         'bully pulpit',\n",
    "         'campaign',\n",
    "         'caucus',\n",
    "         'checks and balances',\n",
    "         'coattails',\n",
    "         'convention',\n",
    "         'dark horse',\n",
    "         'white house',\n",
    "         'delegate',\n",
    "         'demagogue',\n",
    "         'fence mending',\n",
    "         'filibuster',\n",
    "         'fishing expedition',\n",
    "         'front burner',\n",
    "         'gerrymander',\n",
    "         'GOP',\n",
    "         'grass roots',\n",
    "         'ideology',\n",
    "         'incumbent',\n",
    "         'inside the beltway',\n",
    "         'lame duck',\n",
    "         'left-wing',\n",
    "         'lobby',\n",
    "         'machine politics',\n",
    "         'mccarthyism',\n",
    "         'muckraker',\n",
    "         'nomination',\n",
    "         'nominee',\n",
    "         'photo-op',\n",
    "         'platform',\n",
    "         'political party',\n",
    "         'political suicide',\n",
    "         'political',\n",
    "         'poll',\n",
    "         'politicians',\n",
    "         'pork barrel',\n",
    "         'primary',\n",
    "         'pundit',\n",
    "         'reactionary',\n",
    "         'red tape',\n",
    "         'rubber chicken circuit',\n",
    "         'silent majority',\n",
    "         'slate',\n",
    "         'smoke-filled room',\n",
    "         'spin',\n",
    "         'stump',\n",
    "         'swing vote',\n",
    "         'trial balloon',\n",
    "         'whip',\n",
    "         'whistle-stopping:',\n",
    "         'witch hunt'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c32bf63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "political_words_new = []\n",
    "for pol_word in political_words:\n",
    "    political_words_new.append(pol_word.lower())\n",
    "    \n",
    "    for syn in wordnet.synsets(pol_word):\n",
    "        for lm in syn.lemmas():\n",
    "            political_words_new.append(lm.name().replace('_', ' ').lower())#adding into synonyms\n",
    "            if lm.antonyms():\n",
    "                political_words_new.append(lm.antonyms()[0].name().replace('_', ' ').lower()) #adding into antonyms    \n",
    "    \n",
    "political_words_new = set(political_words_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a805f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "246\n"
     ]
    }
   ],
   "source": [
    "print(len(political_words))\n",
    "print(len(political_words_new))\n",
    "#political_words_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0764c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139514, 6)\n"
     ]
    }
   ],
   "source": [
    "dp = DataProcessor(csv_path='../raw_data/', csv_name='dataset_work')\n",
    "df = dp.load_dataset()\n",
    "df = df.sort_values(by=['year', 'month'], ascending=True).reset_index(drop=True)\n",
    "df.shape\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4db3b4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415</td>\n",
       "      <td>36361</td>\n",
       "      <td>2015: Sold Out South Carolina Tea Party Conven...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MYRTLE BEACH, South Carolina     The South Ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                              title  \\\n",
       "0         415  36361  2015: Sold Out South Carolina Tea Party Conven...   \n",
       "\n",
       "     year  month                                            content  \n",
       "0  2015.0    1.0  MYRTLE BEACH, South Carolina     The South Ca...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5032ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99778\n"
     ]
    }
   ],
   "source": [
    "contents = []\n",
    "political_columns = ['Unnamed: 0', 'id', 'title', 'year', 'month', 'content']\n",
    "df_political = pd.DataFrame(columns=political_columns)\n",
    "for _, row in df.iterrows():\n",
    "    row_content = row['content'].lower()\n",
    "    count_words = 0\n",
    "    for political_word in political_words_new:        \n",
    "        if political_word in row_content:\n",
    "            count_words += 1\n",
    "            if count_words >= 5:\n",
    "                contents.append(row_content)\n",
    "                \n",
    "                new_news = {}\n",
    "                new_news['Unnamed: 0'] = row['Unnamed: 0']\n",
    "                new_news['id'] = row['id']\n",
    "                new_news['title'] = row['title']\n",
    "                new_news['year'] = row['year']\n",
    "                new_news['month'] = row['month']\n",
    "                new_news['content'] = row['content']\n",
    "                df_political = df_political.append(new_news, ignore_index=True)\n",
    "                break\n",
    "                \n",
    "print(len(contents))\n",
    "df_political.to_csv(f'../raw_data/political_dataset.csv', header=True, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3dba18fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415</td>\n",
       "      <td>36361</td>\n",
       "      <td>2015: Sold Out South Carolina Tea Party Conven...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MYRTLE BEACH, South Carolina     The South Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>417</td>\n",
       "      <td>57593</td>\n",
       "      <td>Narendra Modi Fast Facts</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(CNN) Here is a look at the life of Indias P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>418</td>\n",
       "      <td>59225</td>\n",
       "      <td>Little Richard Fast Facts</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(CNN) Here is a look at the life of   Archit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>420</td>\n",
       "      <td>60219</td>\n",
       "      <td>Cyclings marathon man attempts 75,000 miles i...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(CNN) While many people are recovering from a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>422</td>\n",
       "      <td>60223</td>\n",
       "      <td>Cops: Georgia police chief on leave after wife...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(CNN) Magazines and websites regularly rank P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99773</th>\n",
       "      <td>139924</td>\n",
       "      <td>208849</td>\n",
       "      <td>Trump administration to name Georgia health of...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>The Trump administration plans to appoint...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99774</th>\n",
       "      <td>139925</td>\n",
       "      <td>208850</td>\n",
       "      <td>Trump tweets a video with a very unfortunate F...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Fox News is probably happy to have the preside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99775</th>\n",
       "      <td>139926</td>\n",
       "      <td>208851</td>\n",
       "      <td>U.S. hospital offers to admit Charlie Gard, th...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>A major New York hospital has offered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99776</th>\n",
       "      <td>139927</td>\n",
       "      <td>208852</td>\n",
       "      <td>How the new Spider-Man is really a John Hugh...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>THE WORDS superhero fatigue have been l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99777</th>\n",
       "      <td>139928</td>\n",
       "      <td>208853</td>\n",
       "      <td>Photographers edit photographers: A closer loo...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>This post is part of the In Sight serie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99778 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      id                                              title  \\\n",
       "0            415   36361  2015: Sold Out South Carolina Tea Party Conven...   \n",
       "1            417   57593                           Narendra Modi Fast Facts   \n",
       "2            418   59225                          Little Richard Fast Facts   \n",
       "3            420   60219  Cyclings marathon man attempts 75,000 miles i...   \n",
       "4            422   60223  Cops: Georgia police chief on leave after wife...   \n",
       "...          ...     ...                                                ...   \n",
       "99773     139924  208849  Trump administration to name Georgia health of...   \n",
       "99774     139925  208850  Trump tweets a video with a very unfortunate F...   \n",
       "99775     139926  208851  U.S. hospital offers to admit Charlie Gard, th...   \n",
       "99776     139927  208852  How the new Spider-Man is really a John Hugh...   \n",
       "99777     139928  208853  Photographers edit photographers: A closer loo...   \n",
       "\n",
       "         year  month                                            content  \n",
       "0      2015.0    1.0  MYRTLE BEACH, South Carolina     The South Ca...  \n",
       "1      2015.0    1.0   (CNN) Here is a look at the life of Indias P...  \n",
       "2      2015.0    1.0   (CNN) Here is a look at the life of   Archit...  \n",
       "3      2015.0    1.0   (CNN) While many people are recovering from a...  \n",
       "4      2015.0    1.0   (CNN) Magazines and websites regularly rank P...  \n",
       "...       ...    ...                                                ...  \n",
       "99773  2017.0    7.0       The Trump administration plans to appoint...  \n",
       "99774  2017.0    7.0  Fox News is probably happy to have the preside...  \n",
       "99775  2017.0    7.0           A major New York hospital has offered...  \n",
       "99776  2017.0    7.0       THE WORDS superhero fatigue have been l...  \n",
       "99777  2017.0    7.0         This post is part of the In Sight serie...  \n",
       "\n",
       "[99778 rows x 6 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_political"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
