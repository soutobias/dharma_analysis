{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d0429da",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "924938f8",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-27 18:43:07.534753: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "# import emoji\n",
    "\n",
    "from scipy import sparse\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#bert\n",
    "from nltk import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# bertopic\n",
    "from bertopic import BERTopic\n",
    "import hdbscan\n",
    "from LeWagon_FinalProject.topic_prepare_graph import TopicPrepareGraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f709410b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>5</td>\n",
       "      <td>641</td>\n",
       "      <td>5_the muslim brotherhood_radical islamic terro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>3</td>\n",
       "      <td>1084</td>\n",
       "      <td>3_hillary clinton is_breitbart hillary clinton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>1</td>\n",
       "      <td>1787</td>\n",
       "      <td>1_trump and russia_ties to russia_russian medd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0</td>\n",
       "      <td>1803</td>\n",
       "      <td>0_health care bill_to repeal obamacare_to repl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2</td>\n",
       "      <td>1158</td>\n",
       "      <td>2_breitbart bernie sanders_bernie sanders is_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>4</td>\n",
       "      <td>897</td>\n",
       "      <td>4_trumps immigration order_trumps immigration ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>6</td>\n",
       "      <td>591</td>\n",
       "      <td>6_york times the_york times in_york times how_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>8</td>\n",
       "      <td>557</td>\n",
       "      <td>8_final presidential debate_first presidential...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>10</td>\n",
       "      <td>487</td>\n",
       "      <td>10_breitbart ted cruz_ted cruz is_trump ted cr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                               Name\n",
       "370      5    641  5_the muslim brotherhood_radical islamic terro...\n",
       "371      3   1084  3_hillary clinton is_breitbart hillary clinton...\n",
       "372      1   1787  1_trump and russia_ties to russia_russian medd...\n",
       "373      0   1803  0_health care bill_to repeal obamacare_to repl...\n",
       "374      2   1158  2_breitbart bernie sanders_bernie sanders is_b...\n",
       "375      4    897  4_trumps immigration order_trumps immigration ...\n",
       "376      6    591  6_york times the_york times in_york times how_...\n",
       "377      8    557  8_final presidential debate_first presidential...\n",
       "378     10    487  10_breitbart ted cruz_ted cruz is_trump ted cr..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_file = '../raw_data/arquivo.csv'\n",
    "topic = TopicPrepareGraph()\n",
    "df_ = topic.prepare_most_important_center(topic_file)\n",
    "df_.iloc[370:379] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4528a7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28017f73",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52fc315f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    text = str(text)\n",
    "    \n",
    "    # remove punctuations\n",
    "    punctuations = string.punctuation\n",
    "    punctuations += '“'\n",
    "    punctuations += '’'\n",
    "    punctuations += '”'\n",
    "    punctuations += '’'\n",
    "    punctuations += ' — '\n",
    "    for punctuation in punctuations:        \n",
    "        text = text.replace(punctuation, ' ')\n",
    "        \n",
    "    # pip install emoji\n",
    "    # remove emoji\n",
    "    text = emoji.get_emoji_regexp().sub(u'', text)\n",
    "    \n",
    "    # remove numbers\n",
    "    words_only = ''.join([i for i in text if not i.isdigit()])\n",
    "    text = words_only\n",
    "    \n",
    "    # remove stop words\n",
    "    stop_words = stopwords.words('english')\n",
    "    #stop_words += stopwords.words('portuguese')\n",
    "    stop_words.append('mr')\n",
    "    stop_words = set(stop_words)\n",
    "\n",
    "    tokenized = word_tokenize(text)\n",
    "    without_stopwords = [word for word in tokenized if not word in stop_words]\n",
    "    text = without_stopwords\n",
    "    \n",
    "    # lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in text]\n",
    "    lemmatized_string = \" \".join(lemmatized)\n",
    "    \n",
    "    return lemmatized_string.lower() # lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14315809",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def generate_topic_info(bert_model, file_name):\n",
    "    df_topic_info = bert_model.get_topic_info()\n",
    "\n",
    "    df_topic_info.to_csv(f'../raw_data/proj_final/not_found/BERTopicInfo_{str(file_name)}.csv', header=True, index=False, encoding='utf-8')\n",
    "    return df_topic_info.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "780ac5c1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def generate_terms(bert_model, file_name):\n",
    "    topics = bert_model.get_topics()\n",
    "    number_of_topics = len(topics)-1\n",
    "    num_of_terms = len(topics[0])\n",
    "\n",
    "    topic_columns = ['topic', 'term', 'weight']\n",
    "\n",
    "    df_topics = pd.DataFrame(columns=topic_columns)\n",
    "    for i in range(-1,number_of_topics): \n",
    "        for j in range(num_of_terms):\n",
    "            new_topic = {}\n",
    "            new_topic['topic'] = topic_model.topic_names[i]\n",
    "            new_topic['term'] = topics[i][j][0]\n",
    "            new_topic['weight'] = round(topics[i][j][1],6)\n",
    "            df_topics = df_topics.append(new_topic, ignore_index=True)\n",
    "\n",
    "    df_topics.to_csv(f'../raw_data/proj_final/not_found/BERTopicTerms_{str(file_name)}.csv', header=True, index=False, encoding='utf-8')\n",
    "    return df_topics.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3356a59",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def correlation_matrix_to_df(df_corr):\n",
    "    list_done = []\n",
    "    lits_item1 = []\n",
    "    lits_item2 = []\n",
    "    list_corr = []\n",
    "\n",
    "    for k in range(1,df_corr.shape[1]):\n",
    "        for i, j in df_corr.iterrows():\n",
    "            #if (df_corr.columns[k] != j[0]) and (j[0] not in list_done):\n",
    "            #if (j[0] not in list_done):\n",
    "            lits_item1.append(df_corr.columns[k])\n",
    "            lits_item2.append(j[0])\n",
    "            list_corr.append(j[k])\n",
    "        list_done.append(df_corr.columns[k])\n",
    "\n",
    "    corr_dict = {'topic1': lits_item1,\n",
    "                 'topic2': lits_item2,\n",
    "                 'similarity': list_corr}\n",
    "    df_res = pd.DataFrame(corr_dict)\n",
    "    df_res = df_res.sort_values(by='similarity', ascending=False).copy()\n",
    "    df_res.reset_index(inplace=True,drop=True)\n",
    "    return df_res.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e008bc9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def generate_topic_similarity(bert_model, file_name):\n",
    "    corr_matrix = bert_model.topic_sim_matrix\n",
    "\n",
    "    topics = bert_model.get_topics()\n",
    "    number_of_topics = len(topics)-1\n",
    "\n",
    "    topic_columns = ['topic']\n",
    "    for i in range(-1,number_of_topics):\n",
    "        topic_columns.append(bert_model.topic_names[i])\n",
    "\n",
    "    df_similarity = pd.DataFrame(columns=topic_columns)\n",
    "    for i in range(-1,number_of_topics):\n",
    "        new_topic = {}\n",
    "        new_topic['topic'] = bert_model.topic_names[i]\n",
    "        for j in range(-1,number_of_topics):\n",
    "            new_topic[bert_model.topic_names[j]] = round(corr_matrix[i,j],6)\n",
    "        df_similarity = df_similarity.append(new_topic, ignore_index=True)\n",
    "        \n",
    "    df_topic_similarity = correlation_matrix_to_df(df_similarity)\n",
    "    df_topic_similarity.to_csv(f'../raw_data/proj_final/not_found/BERTopicSimilarity_{str(file_name)}.csv', header=True, index=False, encoding='utf-8')\n",
    "    return df_topic_similarity.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b674ef6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_topic_documents(cluster_id, condensed_tree):\n",
    "    result_points = np.array([])\n",
    "    result_points_val = np.array([])\n",
    "    \n",
    "    #assert cluster_id > -1, \"The topic's label should be greater than -1!\"\n",
    "    \n",
    "    if cluster_id <= -1:\n",
    "        return result_points.astype(np.int64), result_points_val.astype(np.float64)\n",
    "        \n",
    "    raw_tree = condensed_tree._raw_tree\n",
    "    \n",
    "    # Just the cluster elements of the tree, excluding singleton points\n",
    "    cluster_tree = raw_tree[raw_tree['child_size'] > 1]\n",
    "    \n",
    "    # Get the leaf cluster nodes under the cluster we are considering\n",
    "    leaves = hdbscan.plots._recurse_leaf_dfs(cluster_tree, cluster_id)\n",
    "    \n",
    "    # Now collect up the last remaining points of each leaf cluster (the heart of the leaf) \n",
    "    for leaf in leaves:\n",
    "        #max_lambda = raw_tree['lambda_val'][raw_tree['parent'] == leaf].max()\n",
    "        #points = raw_tree['child'][(raw_tree['parent'] == leaf) & (raw_tree['lambda_val'] == max_lambda)]\n",
    "        #points_val = raw_tree['lambda_val'][(raw_tree['parent'] == leaf) & (raw_tree['lambda_val'] == max_lambda)]\n",
    "        points = raw_tree['child'][(raw_tree['parent'] == leaf)]\n",
    "        points_val = raw_tree['lambda_val'][(raw_tree['parent'] == leaf)]\n",
    "        result_points = np.hstack((result_points, points))\n",
    "        result_points_val = np.hstack((result_points_val, points_val))\n",
    "        \n",
    "    return result_points.astype(np.int64), result_points_val.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d83798d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def generate_topic_documents(bert_model, file_name):\n",
    "    clusterer = bert_model.hdbscan_model\n",
    "    '''tree = clusterer.condensed_tree_\n",
    "    clusters = tree._select_clusters()\n",
    "\n",
    "    number_of_topics = len(clusters)\n",
    "\n",
    "    relevant_columns = ['topic', 'document', 'lambda_val']\n",
    "    df_rel_docs = pd.DataFrame(columns=relevant_columns)\n",
    "\n",
    "    for i in range(-1, number_of_topics):\n",
    "        rel_docs, lambda_vals = get_topic_documents(clusters[i], tree)\n",
    "        topic_name = bert_model.topic_names[i]\n",
    "        for j in range(0, len(rel_docs)):\n",
    "            new_doc_rel = {}\n",
    "            new_doc_rel['topic'] = topic_name\n",
    "            new_doc_rel['document'] = rel_docs[j]\n",
    "            new_doc_rel['lambda_val'] = round(lambda_vals[j],6)\n",
    "            df_rel_docs = df_rel_docs.append(new_doc_rel, ignore_index=True)\n",
    "\n",
    "    df_rel_docs.to_csv(f'../raw_data/proj_final/not_found/BERTopicDocuments_{str(file_name)}.csv', header=True, index=False, encoding='utf-8')\n",
    "    return df_rel_docs.copy()\n",
    "    '''\n",
    "    doc_topic_columns = ['document', 'topic', 'probabilities']\n",
    "    df_doc_topic = pd.DataFrame(columns=doc_topic_columns)\n",
    "\n",
    "    for i, _ in enumerate(clusterer.labels_):\n",
    "        new_doc_topic = {}\n",
    "        new_doc_topic['document'] = i\n",
    "        new_doc_topic['topic'] = clusterer.labels_[i]\n",
    "        new_doc_topic['probabilities'] = clusterer.probabilities_[i]\n",
    "        df_doc_topic = df_doc_topic.append(new_doc_topic, ignore_index=True)\n",
    "    df_doc_topic.to_csv(f'../raw_data/proj_final/not_found/BERTopicDocuments_{str(file_name)}.csv', header=True, index=False, encoding='utf-8')\n",
    "    return df_doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe26cd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3891fcf0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "009c4b88",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99778, 6)\n",
      "(99778, 6)\n",
      "CPU times: user 7.68 s, sys: 1.58 s, total: 9.25 s\n",
      "Wall time: 11.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415</td>\n",
       "      <td>36361</td>\n",
       "      <td>2015: Sold Out South Carolina Tea Party Conven...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MYRTLE BEACH, South Carolina  —   The South Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>417</td>\n",
       "      <td>57593</td>\n",
       "      <td>Narendra Modi Fast Facts</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(CNN) Here is a look at the life of India’s P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>418</td>\n",
       "      <td>59225</td>\n",
       "      <td>Little Richard Fast Facts</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(CNN) Here is a look at the life of   ”Archit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>420</td>\n",
       "      <td>60219</td>\n",
       "      <td>Cycling’s marathon man attempts 75,000 miles i...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(CNN) While many people are recovering from a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>422</td>\n",
       "      <td>60223</td>\n",
       "      <td>Cops: Georgia police chief on leave after wife...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(CNN) Magazines and websites regularly rank P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                              title  \\\n",
       "0         415  36361  2015: Sold Out South Carolina Tea Party Conven...   \n",
       "1         417  57593                           Narendra Modi Fast Facts   \n",
       "2         418  59225                          Little Richard Fast Facts   \n",
       "3         420  60219  Cycling’s marathon man attempts 75,000 miles i...   \n",
       "4         422  60223  Cops: Georgia police chief on leave after wife...   \n",
       "\n",
       "     year  month                                            content  \n",
       "0  2015.0    1.0  MYRTLE BEACH, South Carolina  —   The South Ca...  \n",
       "1  2015.0    1.0   (CNN) Here is a look at the life of India’s P...  \n",
       "2  2015.0    1.0   (CNN) Here is a look at the life of   ”Archit...  \n",
       "3  2015.0    1.0   (CNN) While many people are recovering from a...  \n",
       "4  2015.0    1.0   (CNN) Magazines and websites regularly rank P...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('../raw_data/embeddings/political_dataset.csv')\n",
    "df['title'].fillna('no title', inplace = True)\n",
    "df = df.sort_values(by=['year', 'month'], ascending=True).reset_index(drop=True)\n",
    "\n",
    "#df_processed = df.copy()\n",
    "df_processed = pd.read_csv('../raw_data/embeddings/political_dataset_processed.csv')\n",
    "df_processed['title'].fillna('no title', inplace = True)\n",
    "df_processed = df_processed.sort_values(by=['year', 'month'], ascending=True).reset_index(drop=True)\n",
    "\n",
    "print(df.shape)\n",
    "print(df_processed.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d59d39",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#df_processed['content'] = df_processed['content'].apply(process_text)\n",
    "#df_processed['title'] = df_processed['title'].apply(process_text)\n",
    "#df_processed = df_processed.sort_values(by=['year', 'month'], ascending=True).reset_index(drop=True)\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99bed0a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[df['title'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b0f268",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_processed[df_processed['title'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102150f2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#df_processed.to_csv('../raw_data/embeddings/political_dataset_processed.csv', header=True, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8040d422",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c73959",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/the-best-document-similarity-algorithm-in-2020-a-beginners-guide-a01b9ef8cf05\n",
    "# https://github.com/massanishi/document_similarity_algorithms_experiments\n",
    "# https://outline.com/xYgKZ7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e48c58a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55e6769",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_tfidf_similarity_test():\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # To make uniformed vectors, both documents need to be combined first.\n",
    "    documents.insert(0, base_document)\n",
    "    print(documents)\n",
    "    embeddings = vectorizer.fit_transform(documents)\n",
    "    #print(embeddings.shape)\n",
    "\n",
    "    #cosine_similarities = cosine_similarity(embeddings[0:1], embeddings[1:]).flatten()\n",
    "    cosine_similarities = cosine_similarity(embeddings[0], embeddings[1]).flatten()\n",
    "    '''print(embeddings[0:1])\n",
    "    print('garcia 0')\n",
    "    print(embeddings[0])\n",
    "    print('garcia 1')\n",
    "    print(embeddings[1:])\n",
    "    print('garcia 2')\n",
    "    print(embeddings[1])'''\n",
    "    print(cosine_similarities)\n",
    "\n",
    "    highest_score = 0\n",
    "    highest_score_index = 0\n",
    "    for i, score in enumerate(cosine_similarities):\n",
    "        if highest_score < score:\n",
    "            highest_score = score\n",
    "            highest_score_index = i\n",
    "\n",
    "\n",
    "    most_similar_document = documents[highest_score_index]\n",
    "\n",
    "    print(\"Most similar document by TF-IDF with the score:\", most_similar_document, highest_score)\n",
    "\n",
    "base_document = \"This is an example sentence for the document to be compared\"\n",
    "documents = [\"This is the collection of documents to be compared against the base_document\"]\n",
    "process_tfidf_similarity_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8edae00",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_tfidf_similarity(documents):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
    "    #vectorizer = TfidfVectorizer(ngram_range=(2,2))\n",
    "    #vectorizer = TfidfVectorizer(ngram_range=(3,3))\n",
    "\n",
    "    embeddings = vectorizer.fit_transform(documents)\n",
    "    \n",
    "    #doc_sim_matrix = cosine_similarity(embeddings, embeddings) # problem de memória - Unable to allocate 74.2 GiB for an array with shape (9955646680,) and data type int64\n",
    "    '''\n",
    "    similarity_columns = ['document_1', 'document_2', 'cosine_similarity']\n",
    "    df_similarity = pd.DataFrame(columns=similarity_columns)\n",
    "\n",
    "    for i in range(0, embeddings.shape[0]):\n",
    "        for j in range(0, embeddings.shape[0]):\n",
    "            cosine_similarities = cosine_similarity(embeddings[i], embeddings[j]).flatten()\n",
    "            new_sim = {}\n",
    "            new_sim['document_1'] = i\n",
    "            new_sim['document_2'] = j\n",
    "            new_sim['cosine_similarity'] = round(cosine_similarities[0], 6)\n",
    "            df_similarity = df_similarity.append(new_sim, ignore_index=True)\n",
    "    '''\n",
    "            \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f95bbc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "documents = df['content'].values\n",
    "#tfidf_similarity = process_tfidf_similarity(documents)\n",
    "#tfidf_similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6b009e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#sparse.save_npz('../raw_data/embeddings/TFIDF_processed_ngram_1_1_DocumentsEmbeddings', tfidf_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137499a7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfidf_embeddings = sparse.load_npz('../raw_data/embeddings/TFIDF_raw_DocumentsEmbeddings.npz')\n",
    "tfidf_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5eab0e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cosine_similarities = cosine_similarity(tfidf_embeddings[0], tfidf_embeddings[99000]).flatten()\n",
    "cosine_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd321132",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b41c892",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://www.sbert.net/docs/pretrained_models.html\n",
    "def process_bert_similarity(documents):\n",
    "    model = SentenceTransformer('paraphrase-mpnet-base-v2')\n",
    "    #model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    embeddings_sentences = model.encode(documents)\n",
    "    return embeddings_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720903d3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "documents = df['content'].values#[0:4].values\n",
    "bert_similarity = process_bert_similarity(documents)\n",
    "bert_similarity.shape\n",
    "np.save(f'../raw_data/embeddings/paraphrase-mpnet-base-v2_raw_DocumentsEmbeddings.npy', bert_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f10d3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "documents = df_processed['content'].values#[0:4].values\n",
    "bert_similarity = process_bert_similarity(documents)\n",
    "bert_similarity.shape\n",
    "np.save(f'../raw_data/embeddings/paraphrase-mpnet-base-v2_processed_DocumentsEmbeddings.npy', bert_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dad158",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#print(type(bert_similarity))\n",
    "bert_similarity[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f55a91",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save(f'../raw_data/embeddings/paraphrase-MiniLM-L6-v2_processed_DocumentsEmbeddings.npy', bert_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faafd314",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bert_embeddings = sparse.load_npz('../raw_data/embeddings/paraphrase-MiniLM-L6-v2_raw_DocumentsEmbeddings.npy')\n",
    "bert_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea288cf1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cosine_similarities = cosine_similarity(bert_embeddings[0], bert_embeddings[99000]).flatten()\n",
    "cosine_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33abc90",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe12d86",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/calculate-similarity-the-most-relevant-metrics-in-a-nutshell-9a43564f533e\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import kendalltau\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import jaccard_score\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def calculate_metrics(embeddings, matrix_type):\n",
    "    #metric_columns = ['document_1', 'document_2', 'pearson_corr', 'spearman_corr', 'kendalltau_corr', 'cosine_similarity', 'jaccard_similarity', 'euclidean_distance', 'manhattan_distance']\n",
    "    metric_columns = ['document_1', 'document_2', 'pearson_corr', 'spearman_corr', 'kendalltau_corr', 'cosine_similarity', 'euclidean_distance', 'manhattan_distance']\n",
    "    df_metrics = pd.DataFrame(columns=metric_columns)\n",
    "\n",
    "    for i in range(0, embeddings.shape[0]):\n",
    "        x = embeddings[i]\n",
    "        for j in range(0, embeddings.shape[0]):\n",
    "            y = embeddings[j]\n",
    "            \n",
    "            # calculate Pearson's correlation\n",
    "            if matrix_type == 'npy':\n",
    "                pearson_corr, _ = pearsonr(x, y)\n",
    "            else:\n",
    "                pearson_corr, _ = pearsonr(x.toarray()[0], y.toarray()[0])\n",
    "\n",
    "            # calculate Spearman's correlation\n",
    "            if matrix_type == 'npy':\n",
    "                spearman_corr, _ = spearmanr(x, y)\n",
    "            else:\n",
    "                spearman_corr, _ = spearmanr(x.toarray()[0], y.toarray()[0])\n",
    "\n",
    "            # calculate Pearson’s correlation\n",
    "            if matrix_type == 'npy':\n",
    "                kendalltau_corr, _ = kendalltau(x, y)\n",
    "            else:\n",
    "                kendalltau_corr, _ = kendalltau(x.toarray()[0], y.toarray()[0])\n",
    "\n",
    "            # calculate Cosine Similarity\n",
    "            # reshape the vectors x and y using .reshape(1, -1) to compute the cosine similarity for a single sample\n",
    "            if matrix_type == 'npy':\n",
    "                cos_sim = cosine_similarity(x.reshape(1,-1), y.reshape(1,-1)).flatten()[0]\n",
    "            else:\n",
    "                cos_sim = cosine_similarity(x, y).flatten()[0]\n",
    "\n",
    "            # calculate Jaccard Similarity\n",
    "            # accard similarity is for comparing two binary vectors (sets)\n",
    "            #jacc = jaccard_score(x,y)\n",
    "\n",
    "            # calculate Euclidean Distance\n",
    "            # Compared to the Cosine and Jaccard similarity, Euclidean distance is not used very often in the context of NLP applications\n",
    "            if matrix_type == 'npy':\n",
    "                dst_euclidean = distance.euclidean(x, y)\n",
    "            else:\n",
    "                dst_euclidean = distance.euclidean(x.toarray()[0], y.toarray()[0])\n",
    "\n",
    "            # calculate Manhattan Distance\n",
    "            if matrix_type == 'npy':\n",
    "                dst_cityblock = distance.cityblock(x, y)\n",
    "            else:\n",
    "                dst_cityblock = distance.cityblock(x.toarray()[0], y.toarray()[0])\n",
    "    \n",
    "            new_metric = {}\n",
    "            new_metric['document_1'] = i\n",
    "            new_metric['document_2'] = j\n",
    "            new_metric['pearson_corr'] = round(pearson_corr, 6)\n",
    "            new_metric['spearman_corr'] = round(spearman_corr, 6)\n",
    "            new_metric['kendalltau_corr'] = round(kendalltau_corr, 6)\n",
    "            new_metric['cosine_similarity'] = round(cos_sim, 6)\n",
    "            #new_metric['jaccard_similarity'] = round(jacc[0], 6)\n",
    "            new_metric['euclidean_distance'] = round(dst_euclidean, 6)\n",
    "            new_metric['manhattan_distance'] = round(dst_cityblock, 6)\n",
    "            df_metrics = df_metrics.append(new_metric, ignore_index=True)\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01d309a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from LeWagon_FinalProject.similarity import Similarity\n",
    "\n",
    "sim = Similarity()\n",
    "#tfidf_embeddings = sparse.load_npz('../raw_data/embeddings/TFIDF_raw_ngram_1_1_DocumentsEmbeddings.npz')\n",
    "#df_metrics_result = sim.calculate_metrics_npz(tfidf_embeddings[0:4])\n",
    "\n",
    "deep_embeddings = np.load('../raw_data/embeddings/paraphrase-mpnet-base-v2_raw_DocumentsEmbeddings.npy')\n",
    "df_metrics_result = sim.calculate_metrics_npy(deep_embeddings[0:2])\n",
    "df_metrics_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba9908",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tfidf_embeddings = sparse.load_npz('../raw_data/embeddings/TFIDF_raw_ngram_1_1_DocumentsEmbeddings.npz')\n",
    "df_metrics = calculate_metrics(tfidf_embeddings[0:4], 'npz')\n",
    "df_metrics['file'] = 'TFIDF_raw_ngram_1_1_DocumentsEmbeddings.npz'\n",
    "df_metrics_result = df_metrics.copy()\n",
    "\n",
    "files = ['TFIDF_processed_ngram_1_1_DocumentsEmbeddings.npz',\n",
    "         'TFIDF_raw_ngram_2_2_DocumentsEmbeddings.npz',\n",
    "         'TFIDF_processed_ngram_2_2_DocumentsEmbeddings.npz',\n",
    "         'TFIDF_raw_ngram_3_3_DocumentsEmbeddings.npz',\n",
    "         'TFIDF_processed_ngram_3_3_DocumentsEmbeddings.npz',\n",
    "         'paraphrase-MiniLM-L6-v2_processed_DocumentsEmbeddings.npy',\n",
    "         'paraphrase-MiniLM-L6-v2_raw_DocumentsEmbeddings.npy',\n",
    "         'paraphrase-mpnet-base-v2_processed_DocumentsEmbeddings.npy',\n",
    "         'paraphrase-mpnet-base-v2_raw_DocumentsEmbeddings.npy'\n",
    "        ]\n",
    "\n",
    "for file in files:\n",
    "    if '.npy' in file:\n",
    "        tfidf_embeddings = np.load('../raw_data/embeddings/'+file)\n",
    "        matrix_type = 'npy'\n",
    "    else:\n",
    "        tfidf_embeddings = sparse.load_npz('../raw_data/embeddings/'+file)\n",
    "        matrix_type = 'npz'\n",
    "        \n",
    "    df_metrics = calculate_metrics(tfidf_embeddings[0:4], matrix_type)\n",
    "    df_metrics['file'] = file   \n",
    "    df_metrics_result = pd.concat([df_metrics_result, df_metrics], ignore_index=True)\n",
    "    del df_metrics\n",
    "    del tfidf_embeddings\n",
    "    \n",
    "df_metrics_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1457a5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_metrics_result.to_csv('../raw_data/embeddings/metrics_tests.csv', header=True, index=False, encoding='utf-8')\n",
    "#df_metrics_result = pd.read_csv('../raw_data/embeddings/metrics_tests.csv')\n",
    "df_metrics_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc33cc1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BERTopic title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a89bd2e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "topic_model_x = BERTopic.load('../raw_data/proj_final/BERTopic_model_2_2_raw_title_paraphrase-mpnet-base-v2')\n",
    "clusterer = topic_model_x.hdbscan_model\n",
    "del topic_model_x\n",
    "docs = []\n",
    "for i, topic_ind in enumerate(clusterer.labels_):\n",
    "    if topic_ind == -1:\n",
    "        docs.append(df['title'].iloc[i])\n",
    "len(docs)\n",
    "\n",
    "df_temp = pd.DataFrame(docs, columns=['title'])\n",
    "df_temp.to_csv(f'../raw_data/proj_final/not_found/{0}_documents.csv', header=True, index=True, encoding='utf-8')\n",
    "\n",
    "sentence_model = SentenceTransformer(\"paraphrase-mpnet-base-v2\")\n",
    "topic_model = BERTopic(min_topic_size=15, language='english', calculate_probabilities=False, n_gram_range=(2,2), embedding_model=sentence_model)\n",
    "topic_model.fit_transform(docs)\n",
    "topic_model.save('../raw_data/proj_final/not_found/BERTopic_model_0_2_2_raw_title_paraphrase-mpnet-base-v2')\n",
    "\n",
    "\n",
    "#topic_model = BERTopic.load('../raw_data/proj_final/not_found/BERTopic_model_0_2_2_raw_title_paraphrase-mpnet-base-v2')\n",
    "\n",
    "df_topic_info = generate_topic_info(topic_model, '0_2_2_RawTitle_paraphrase-mpnet-base-v2')\n",
    "df_terms = generate_terms(topic_model, '0_2_2_RawTitle_paraphrase-mpnet-base-v2')\n",
    "df_topic_similarity = generate_topic_similarity(topic_model, '0_2_2_RawTitle_paraphrase-mpnet-base-v2')\n",
    "df_topic_documents = generate_topic_documents(topic_model, '0_2_2_RawTitle_paraphrase-mpnet-base-v2')\n",
    "\n",
    "del docs\n",
    "del topic_model\n",
    "del sentence_model\n",
    "del df_topic_info\n",
    "del df_terms\n",
    "del df_topic_similarity\n",
    "del df_topic_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ac8e4c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for k in range(1, 1000):\n",
    "    df_docs_not_found = pd.read_csv(f'../raw_data/proj_final/not_found/{k-1}_documents.csv')\n",
    "    topic_model_x = BERTopic.load(f'../raw_data/proj_final/not_found/BERTopic_model_{k-1}_1_1_raw_title_paraphrase-mpnet-base-v2')\n",
    "    clusterer = topic_model_x.hdbscan_model\n",
    "    del topic_model_x\n",
    "    docs = []\n",
    "    for i, topic_ind in enumerate(clusterer.labels_):\n",
    "        if topic_ind == -1:\n",
    "            docs.append(df_docs_not_found['title'].iloc[i])\n",
    "    del df_docs_not_found\n",
    "    del clusterer\n",
    "    print(len(docs))\n",
    "    if len(docs) <= 15:\n",
    "        break\n",
    "        \n",
    "    df_temp = pd.DataFrame(docs)\n",
    "    df_temp.to_csv(f'../raw_data/proj_final/not_found/{k}_documents.csv', header=False, index=True, encoding='utf-8')\n",
    "    del df_temp\n",
    "    \n",
    "    sentence_model = SentenceTransformer(\"paraphrase-mpnet-base-v2\")\n",
    "    topic_model = BERTopic(min_topic_size=15, language='english', calculate_probabilities=False, n_gram_range=(2,2), embedding_model=sentence_model)\n",
    "    topic_model.fit_transform(docs)\n",
    "    topic_model.save(f'../raw_data/proj_final/not_found/BERTopic_model_{k}_2_2_raw_title_paraphrase-mpnet-base-v2')\n",
    "    \n",
    "    df_topic_info = generate_topic_info(topic_model, f'{k}_2_2_RawTitle_paraphrase-mpnet-base-v2')\n",
    "    df_terms = generate_terms(topic_model, f'{k}_2_2_RawTitle_paraphrase-mpnet-base-v2')\n",
    "    df_topic_similarity = generate_topic_similarity(topic_model, f'{k}_2_2_RawTitle_paraphrase-mpnet-base-v2')\n",
    "    df_topic_documents = generate_topic_documents(topic_model, f'{k}_2_2_RawTitle_paraphrase-mpnet-base-v2')\n",
    "    \n",
    "    del docs\n",
    "    del topic_model\n",
    "    del sentence_model\n",
    "    del df_topic_info\n",
    "    del df_terms\n",
    "    del df_topic_similarity\n",
    "    del df_topic_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85baf476",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#docs = df['title'].values\n",
    "#topic_model = BERTopic(min_topic_size=15, language='english', calculate_probabilities=False, n_gram_range=(1,1))\n",
    "#topic_model.fit_transform(docs)\n",
    "#topic_model.save('../raw_data/embeddings/berttopic/BERTopic_model_1_1_raw_title')\n",
    "topic_model = BERTopic.load('../raw_data/embeddings/berttopic/BERTopic_model_1_1_raw_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0af9930",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_topic_info = generate_topic_info(topic_model, '1_1_RawTitle')\n",
    "df_terms = generate_terms(topic_model, '1_1_RawTitle')\n",
    "df_topic_similarity = generate_topic_similarity(topic_model, '1_1_RawTitle')\n",
    "df_topic_documents = generate_topic_documents(topic_model, '1_1_RawTitle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e34e28e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#docs = df_processed['title'].values\n",
    "#topic_model = BERTopic(min_topic_size=15, language='english', calculate_probabilities=False, n_gram_range=(1,1))\n",
    "#topic_model.fit_transform(docs)\n",
    "#topic_model.save('../raw_data/embeddings/berttopic/BERTopic_model_1_1_processed_title')\n",
    "topic_model = BERTopic.load('../raw_data/embeddings/berttopic/BERTopic_model_1_1_processed_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadc579d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_topic_info = generate_topic_info(topic_model, '1_1_ProcessedTitle')\n",
    "df_terms = generate_terms(topic_model, '1_1_ProcessedTitle')\n",
    "df_topic_similarity = generate_topic_similarity(topic_model, '1_1_ProcessedTitle')\n",
    "df_topic_documents = generate_topic_documents(topic_model, '1_1_ProcessedTitle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a971df6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#docs = df['title'].values\n",
    "#topic_model = BERTopic(min_topic_size=15, language='english', calculate_probabilities=False, n_gram_range=(2,2))\n",
    "#topic_model.fit_transform(docs)\n",
    "#topic_model.save('../raw_data/embeddings/berttopic/BERTopic_model_2_2_raw_title')\n",
    "topic_model = BERTopic.load('../raw_data/embeddings/berttopic/BERTopic_model_2_2_raw_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e53640a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_topic_info = generate_topic_info(topic_model, '2_2_RawTitle')\n",
    "df_terms = generate_terms(topic_model, '2_2_RawTitle')\n",
    "df_topic_similarity = generate_topic_similarity(topic_model, '2_2_RawTitle')\n",
    "df_topic_documents = generate_topic_documents(topic_model, '2_2_RawTitle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8022ea",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#docs = df_processed['title'].values\n",
    "#topic_model = BERTopic(min_topic_size=15, language='english', calculate_probabilities=False, n_gram_range=(2,2))\n",
    "#topic_model.fit_transform(docs)\n",
    "#topic_model.save('../raw_data/embeddings/berttopic/BERTopic_model_2_2_processed_title')\n",
    "topic_model = BERTopic.load('../raw_data/embeddings/berttopic/BERTopic_model_2_2_processed_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832e635",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_topic_info = generate_topic_info(topic_model, '2_2_ProcessedTitle')\n",
    "df_terms = generate_terms(topic_model, '2_2_ProcessedTitle')\n",
    "df_topic_similarity = generate_topic_similarity(topic_model, '2_2_ProcessedTitle')\n",
    "df_topic_documents = generate_topic_documents(topic_model, '2_2_ProcessedTitle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6627304d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#docs = df['title'].values\n",
    "#topic_model = BERTopic(min_topic_size=15, language='english', calculate_probabilities=False, n_gram_range=(3,3))\n",
    "#topic_model.fit_transform(docs)\n",
    "#topic_model.save('../raw_data/embeddings/berttopic/BERTopic_model_3_3_raw_title')\n",
    "topic_model = BERTopic.load('../raw_data/embeddings/berttopic/BERTopic_model_3_3_raw_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25993cb4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_topic_info = generate_topic_info(topic_model, '3_3_RawTitle')\n",
    "df_terms = generate_terms(topic_model, '3_3_RawTitle')\n",
    "df_topic_similarity = generate_topic_similarity(topic_model, '3_3_RawTitle')\n",
    "df_topic_documents = generate_topic_documents(topic_model, '3_3_RawTitle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39da2166",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#docs = df_processed['title'].values\n",
    "#topic_model = BERTopic(min_topic_size=15, language='english', calculate_probabilities=False, n_gram_range=(3,3))\n",
    "#topic_model.fit_transform(docs)\n",
    "#topic_model.save('../raw_data/embeddings/berttopic/BERTopic_model_3_3_Processed_title')\n",
    "topic_model = BERTopic.load('../raw_data/embeddings/berttopic/BERTopic_model_3_3_Processed_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48352675",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_topic_info = generate_topic_info(topic_model, '3_3_ProcessedTitle')\n",
    "df_terms = generate_terms(topic_model, '3_3_ProcessedTitle')\n",
    "df_topic_similarity = generate_topic_similarity(topic_model, '3_3_ProcessedTitle')\n",
    "df_topic_documents = generate_topic_documents(topic_model, '3_3_ProcessedTitle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f99d92",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c1395",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "deep_embeddings = np.load('../raw_data/embeddings/paraphrase-mpnet-base-v2_raw_DocumentsEmbeddings.npy')\n",
    "deep_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422e1daf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa38e4fd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "k = deep_embeddings[0]\n",
    "len(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bf43ca",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cos_sim = cosine_similarity(deep_embeddings[1].reshape(1, -1), deep_embeddings)\n",
    "cos_sim = cos_sim.reshape(-1, 1)[:,0]\n",
    "cos_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca98dc4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save('../raw_data/similarity/teste.npy', cos_sim)\n",
    "cos_sim1 = np.load('../raw_data/similarity/teste.npy')\n",
    "cos_sim1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba0659",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pearson_corr = pearsonr(deep_embeddings, deep_embeddings)\n",
    "pearson_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281cea11",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cos_sim = cosine_similarity(deep_embeddings[0:2], deep_embeddings[0:2])\n",
    "cos_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415d3ef",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save('../raw_data/similarity/similarity_paraphrase-mpnet-base-v2_raw_DocumentsEmbeddings.npy', cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c1eea0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cos_sim = np.load('../raw_data/similarity/similarity_paraphrase-mpnet-base-v2_raw_DocumentsEmbeddings_01.npy')\n",
    "cos_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e34ebcf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62675fb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "deep_embeddings[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f844427",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_int = 10\n",
    "inc = deep_embeddings.shape[0]//10\n",
    "\n",
    "start_at = 0\n",
    "end_at = inc\n",
    "for i in range(0,n_int):\n",
    "    print(f'{start_at} - {end_at} : {i}')\n",
    "    start_at = end_at\n",
    "    end_at = start_at + inc\n",
    "\n",
    "if start_at <= deep_embeddings.shape[0]:\n",
    "    end_at = deep_embeddings.shape[0]\n",
    "    print(f'{start_at} - {end_at} : {i+1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df73947a",
   "metadata": {},
   "source": [
    "## Check Bertopic Documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f14b8bcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent</th>\n",
       "      <th>child</th>\n",
       "      <th>lambda_val</th>\n",
       "      <th>child_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99778</td>\n",
       "      <td>41185</td>\n",
       "      <td>0.119959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99778</td>\n",
       "      <td>35916</td>\n",
       "      <td>0.119960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99778</td>\n",
       "      <td>41105</td>\n",
       "      <td>0.119960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99778</td>\n",
       "      <td>41447</td>\n",
       "      <td>0.119961</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99778</td>\n",
       "      <td>35967</td>\n",
       "      <td>0.119961</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101705</th>\n",
       "      <td>101710</td>\n",
       "      <td>71624</td>\n",
       "      <td>15.135028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101706</th>\n",
       "      <td>101710</td>\n",
       "      <td>95457</td>\n",
       "      <td>15.135028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101707</th>\n",
       "      <td>101710</td>\n",
       "      <td>75935</td>\n",
       "      <td>15.135028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101708</th>\n",
       "      <td>101710</td>\n",
       "      <td>50415</td>\n",
       "      <td>15.135028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101709</th>\n",
       "      <td>101710</td>\n",
       "      <td>89408</td>\n",
       "      <td>15.135028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101710 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        parent  child  lambda_val  child_size\n",
       "0        99778  41185    0.119959           1\n",
       "1        99778  35916    0.119960           1\n",
       "2        99778  41105    0.119960           1\n",
       "3        99778  41447    0.119961           1\n",
       "4        99778  35967    0.119961           1\n",
       "...        ...    ...         ...         ...\n",
       "101705  101710  71624   15.135028           1\n",
       "101706  101710  95457   15.135028           1\n",
       "101707  101710  75935   15.135028           1\n",
       "101708  101710  50415   15.135028           1\n",
       "101709  101710  89408   15.135028           1\n",
       "\n",
       "[101710 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://hdbscan.readthedocs.io/en/latest/basic_hdbscan.html\n",
    "\n",
    "topic_model = BERTopic.load('../raw_data/proj_final/BERTopic_model_2_2_raw_title_paraphrase-mpnet-base-v2')\n",
    "#generate_topic_documents(topic_model, 'porra')\n",
    "\n",
    "clusterer = topic_model.hdbscan_model\n",
    "df_hdbscan = clusterer.condensed_tree_.to_pandas()\n",
    "df_hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcc227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "doc_topic_columns = ['document', 'topic', 'probabilities']\n",
    "df_doc_topic = pd.DataFrame(columns=doc_topic_columns)\n",
    "\n",
    "for i, _ in enumerate(clusterer.labels_):\n",
    "    new_doc_topic = {}\n",
    "    new_doc_topic['document'] = i\n",
    "    new_doc_topic['topic'] = clusterer.labels_[i]\n",
    "    new_doc_topic['probabilities'] = clusterer.probabilities_[i]\n",
    "    df_doc_topic = df_doc_topic.append(new_doc_topic, ignore_index=True)\n",
    "df_doc_topic.to_csv('../raw_data/proj_final/title_paraphrase-mpnet-base-v2_documents_topics.csv', header=True, index=False, encoding='utf-8')\n",
    "del df_doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b78bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clusterer.labels_.max())\n",
    "i_ind = 0\n",
    "i_count = 0\n",
    "for c in clusterer.probabilities_:\n",
    "    if (c == 0) and (clusterer.labels_[i_ind] != -1):\n",
    "        print(f'{i_ind} - {c} {clusterer.labels_[i_ind]}')\n",
    "        i_count += 1\n",
    "    i_ind += 1\n",
    "print(i_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30d1bc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='$\\\\lambda$ value'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "#clusterer.condensed_tree_.plot(select_clusters=True, selection_palette=sns.color_palette('deep', 8))\n",
    "clusterer.condensed_tree_.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b382aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_info = topic_model.get_topic_info()\n",
    "#df_topic_info.to_csv(f'../raw_data/embeddings/berttopic/BERTopicInfo_{str(file_name)}.csv', header=True, index=False, encoding='utf-8')\n",
    "df_topic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41bdef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(\"../raw_data/embeddings/merda_doc_topics.csv\", clusterer.labels_, delimiter=\",\")\n",
    "x = 0\n",
    "for l in clusterer.labels_:\n",
    "    #if l > x:\n",
    "    if l == -1:\n",
    "        x += 1\n",
    "        #x = l\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee40bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_hdbscan.to_csv(f'../raw_data/embeddings/porra.csv', header=True, index=False, encoding='utf-8')\n",
    "tree = clusterer.condensed_tree_\n",
    "clusters = tree._select_clusters()\n",
    "print(len(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65419b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = topic_model\n",
    "\n",
    "clusterer = bert_model.hdbscan_model\n",
    "tree = clusterer.condensed_tree_\n",
    "clusters = tree._select_clusters()\n",
    "\n",
    "number_of_topics = len(clusters)\n",
    "print(number_of_topics)\n",
    "\n",
    "relevant_columns = ['topic', 'document', 'lambda_val']\n",
    "df_rel_docs = pd.DataFrame(columns=relevant_columns)\n",
    "\n",
    "for i in range(-1, number_of_topics):\n",
    "    cluster_id = clusters[i]\n",
    "    condensed_tree = tree\n",
    "    topic_name = bert_model.topic_names[i]\n",
    "    \n",
    "    print(topic_name)\n",
    "    \n",
    "    result_points = np.array([])\n",
    "    result_points_val = np.array([])\n",
    "\n",
    "        \n",
    "    raw_tree = condensed_tree._raw_tree\n",
    "    \n",
    "    # Just the cluster elements of the tree, excluding singleton points\n",
    "    #cluster_tree = raw_tree[raw_tree['child_size'] > 1]\n",
    "    \n",
    "    # Get the leaf cluster nodes under the cluster we are considering\n",
    "    leaves = hdbscan.plots._recurse_leaf_dfs(raw_tree, cluster_id)\n",
    "    print(cluster_id)\n",
    "    \n",
    "    #print(type(leaves))\n",
    "    print(len(leaves))\n",
    "    #print(leaves[0])\n",
    "    \n",
    "    #print(raw_tree.shape)\n",
    "    \n",
    "    #np.save('../raw_data/porra.npy', raw_tree)\n",
    "    #for line in raw_tree:\n",
    "        #print(line[1])\n",
    "        #(raw_tree['parent'] == leaf)\n",
    "    \n",
    "    # Now collect up the last remaining points of each leaf cluster (the heart of the leaf) \n",
    "    \n",
    "    porra = 0\n",
    "    for leaf in leaves:\n",
    "        #print(leaf)\n",
    "        porra += 1\n",
    "        #max_lambda = raw_tree['lambda_val'][raw_tree['parent'] == leaf].max()\n",
    "        #points = raw_tree['child'][(raw_tree['parent'] == leaf) & (raw_tree['lambda_val'] == max_lambda)]\n",
    "        #points_val = raw_tree['lambda_val'][(raw_tree['parent'] == leaf) & (raw_tree['lambda_val'] == max_lambda)]\n",
    "        '''points = raw_tree['child'][(raw_tree['parent'] == leaf)]\n",
    "        points_val = raw_tree['lambda_val'][(raw_tree['parent'] == leaf)]\n",
    "        result_points = np.hstack((result_points, points))\n",
    "        result_points_val = np.hstack((result_points_val, points_val))\n",
    "    '''\n",
    "    print(porra)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f77f5b",
   "metadata": {},
   "source": [
    "## Similarity between documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9575378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "docs_similarity = np.load('../raw_data/proj_final/similarity/0_cosine_similarity.npy')\n",
    "ind = 0\n",
    "for sim in docs_similarity:\n",
    "    ind += 1\n",
    "    print(sim)\n",
    "    if ind > 5:\n",
    "        break\n",
    "\n",
    "print(' ********** ')\n",
    "print(docs_similarity[len(docs_similarity)-5])\n",
    "print(docs_similarity[len(docs_similarity)-4])\n",
    "print(docs_similarity[len(docs_similarity)-3])\n",
    "print(docs_similarity[len(docs_similarity)-2])\n",
    "print(docs_similarity[len(docs_similarity)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542138c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(docs_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sim_columns = ['document', 'most_similar_doc', 'higher_cosine_similarity']\n",
    "df_most_sim = pd.DataFrame(columns=sim_columns)\n",
    "most_sim_doc_pair = ['-1_-1']\n",
    "print_calc = 0\n",
    "for i in range(0, 99777):\n",
    "    print_calc += 1\n",
    "    doc_similarity = np.load(f'../raw_data/proj_final/similarity/{i}_cosine_similarity.npy')\n",
    "    doc_id = i\n",
    "    higher_sim = -1\n",
    "    doc_id_sim = -1\n",
    "    for j, sim in enumerate(doc_similarity):\n",
    "        if i != j:\n",
    "            doc_pair = f'{j}_{i}'\n",
    "            if (doc_similarity[j] > higher_sim) and (doc_pair not in most_sim_doc_pair):\n",
    "                higher_sim = doc_similarity[j]\n",
    "                doc_id_sim = j\n",
    "    new_doc = {}\n",
    "    new_doc['document'] = doc_id\n",
    "    new_doc['most_similar_doc'] = doc_id_sim\n",
    "    new_doc['higher_cosine_similarity'] = higher_sim\n",
    "    df_most_sim = df_most_sim.append(new_doc, ignore_index=True)\n",
    "    most_sim_doc_pair.append(f'{doc_id}_{doc_id_sim}')\n",
    "    if print_calc > 1000:\n",
    "        print(i)\n",
    "        print_calc = 0\n",
    "df_most_sim.to_csv('../raw_data/proj_final/most_similar_docs.csv', header=True, index=False, encoding='utf-8')\n",
    "del df_most_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b79ee878",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_sim = pd.read_csv('../raw_data/proj_final/most_similar_docs.csv')\n",
    "df_most_sim = df_most_sim.sort_values(by=['higher_cosine_similarity'], ascending=False).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34ec7064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>most_similar_doc</th>\n",
       "      <th>higher_cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8529</th>\n",
       "      <td>8529.0</td>\n",
       "      <td>12853.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44767</th>\n",
       "      <td>44767.0</td>\n",
       "      <td>44787.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60443</th>\n",
       "      <td>60443.0</td>\n",
       "      <td>60789.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>4046.0</td>\n",
       "      <td>4072.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23646</th>\n",
       "      <td>23646.0</td>\n",
       "      <td>23676.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69022</th>\n",
       "      <td>69022.0</td>\n",
       "      <td>62955.0</td>\n",
       "      <td>0.600067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34861</th>\n",
       "      <td>34861.0</td>\n",
       "      <td>96086.0</td>\n",
       "      <td>0.600053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4884</th>\n",
       "      <td>4884.0</td>\n",
       "      <td>31243.0</td>\n",
       "      <td>0.600036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27049</th>\n",
       "      <td>27049.0</td>\n",
       "      <td>73711.0</td>\n",
       "      <td>0.600026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98168</th>\n",
       "      <td>98168.0</td>\n",
       "      <td>73247.0</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86971 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       document  most_similar_doc  higher_cosine_similarity\n",
       "8529     8529.0           12853.0                  1.000000\n",
       "44767   44767.0           44787.0                  1.000000\n",
       "60443   60443.0           60789.0                  1.000000\n",
       "4046     4046.0            4072.0                  1.000000\n",
       "23646   23646.0           23676.0                  1.000000\n",
       "...         ...               ...                       ...\n",
       "69022   69022.0           62955.0                  0.600067\n",
       "34861   34861.0           96086.0                  0.600053\n",
       "4884     4884.0           31243.0                  0.600036\n",
       "27049   27049.0           73711.0                  0.600026\n",
       "98168   98168.0           73247.0                  0.600000\n",
       "\n",
       "[86971 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_most_sim = df_most_sim[df_most_sim['higher_cosine_similarity'] >= 0.6]\n",
    "df_most_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdd7eab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>most_similar_doc</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33105</th>\n",
       "      <td>69845.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10637</th>\n",
       "      <td>23427.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22532</th>\n",
       "      <td>48349.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       most_similar_doc  document\n",
       "33105           69845.0        15\n",
       "10637           23427.0        15\n",
       "22532           48349.0        15"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x = df_most_sim.groupby(by=[\"most_similar_doc\"])['document'].count().mean()\n",
    "#x = df_most_sim.groupby(by=[\"most_similar_doc\"])['document', 'higher_cosine_similarity'].count().mean()\n",
    "x = df_most_sim.groupby(by=[\"most_similar_doc\"])['document'].count()\n",
    "x = x.to_frame().reset_index()\n",
    "# x['document'].sum()\n",
    "x.sort_values(by=['document'], ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af275cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x[x['document'] >= 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95d69116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33987612"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sim = np.load('../raw_data/proj_final/similarity/69845_cosine_similarity.npy')\n",
    "doc_sim[28672]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99f4e492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78258556"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sim = np.load('../raw_data/proj_final/similarity/23427_cosine_similarity.npy')\n",
    "doc_sim[48349]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
